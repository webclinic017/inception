{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "# imports\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, time, random\n",
    "import os.path, urllib\n",
    "from io import StringIO\n",
    "from urllib.request import urlopen\n",
    "from pandas.io.json import json_normalize\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config.json\n"
     ]
    }
   ],
   "source": [
    "# config and mappings\n",
    "conf_file = 'config.json'\n",
    "config = load_config(conf_file)\n",
    "\n",
    "UNIVERSE = config['symbols']\n",
    "BUCKET_NAME = config[\"bucket_name\"]\n",
    "MIN_MAX_SLEEP = config[\"min_max_sleep\"]\n",
    "MAX_SYMBOLS = config[\"max_symbols_request\"]\n",
    "S3_STORE = config['s3_store']\n",
    "fname = config['filename_fmt']\n",
    "\n",
    "s3 = boto3.resource('s3', 'us-west-2')\n",
    "bucket = s3.Bucket(BUCKET_NAME)\n",
    "\n",
    "url_key = 'url'\n",
    "enc_key = 'enc_key'\n",
    "enc_val = 'enc_val'\n",
    "storage_path = 'store_path'\n",
    "\n",
    "query_map = {\n",
    "    'summary': {\n",
    "        url_key:'https://query1.finance.yahoo.com/v10/finance/quoteSummary/{0}?formatted=true&lang=en-US&region=US&{1}&corsDomain=finance.yahoo.com',\n",
    "        enc_key: 'modules',\n",
    "        enc_val:'defaultKeyStatistics,assetProfile,financialData,balanceSheetHistory,balanceSheetHistoryQuarterly,cashflowStatementHistory,cashflowStatementHistoryQuarterly,incomeStatementHistory,incomeStatementHistoryQuarterly,calendarEvents,earnings,earningsHistory,earningsTrend,recommendationTrend,upgradeDowngradeHistory,indexTrend,fundOwnership,insiderHolders,institutionOwnership,majorDirectHolders,majorHoldersBreakdown,netSharePurchaseActivity'\n",
    "    },\n",
    "    'option': {\n",
    "        url_key:'https://query1.finance.yahoo.com/v7/finance/options/{0}?formatted=true&lang=en-US&region=US&straddle=false&{1}&corsDomain=finance.yahoo.com',\n",
    "        enc_key: 'date'\n",
    "    },\n",
    "    'quote':{\n",
    "        url_key:'https://query1.finance.yahoo.com/v7/finance/quote?formatted=true&lang=en-US&region=US&{0}&corsDomain=finance.yahoo.com',\n",
    "        enc_key: 'symbols'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S3_STORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "code_folding": [
     4,
     11,
     18,
     22,
     29,
     48,
     59,
     65
    ]
   },
   "outputs": [],
   "source": [
    "# data gathering and storage functions\n",
    "comma_join = lambda x, y: x + ',' + y\n",
    "getChildrenList = lambda tempResult, parent: tempResult[parent]['result']\n",
    "\n",
    "def save_config(config, fname):\n",
    "    with open(fname, 'w') as file:\n",
    "        data = json.dumps(config, indent=1)\n",
    "        file.write(data)\n",
    "        file.close()\n",
    "        print('Saving', fname)\n",
    "\n",
    "def load_config(fname):\n",
    "    with open(fname, 'r') as file:\n",
    "        data = file.read()\n",
    "        file.close()\n",
    "        print('Loading', fname)\n",
    "        return json.loads(data)\n",
    "\n",
    "def run_sleeper(min_s, max_s):\n",
    "    sleep_time = random.randint(min_s, max_s)\n",
    "    time.sleep(sleep_time)\n",
    "    \n",
    "def url_open(url):\n",
    "    run_sleeper(MIN_MAX_SLEEP[0], MIN_MAX_SLEEP[1])\n",
    "    usock = urlopen(url)\n",
    "    data = usock.read()\n",
    "    usock.close()\n",
    "    return data\n",
    "\n",
    "def get_data(symbol, dataset, encoded_params):\n",
    "    url = query_map[dataset][url_key]\n",
    "    data = url_open(url.format(symbol, encoded_params))\n",
    "    return data\n",
    "\n",
    "def save_to_file(data, path, fname):\n",
    "    \n",
    "    if (S3_STORE):\n",
    "        file_key = path + fname\n",
    "        print(file_key)\n",
    "        bucket.put_object(Body=data, Key=file_key)\n",
    "        return\n",
    "    \n",
    "    write_method = 'w' + ('b' if type(data) is bytes else '')\n",
    "    bucket_path = './' + BUCKET_NAME + '/'\n",
    "    try: file = open(bucket_path + path + fname, write_method)\n",
    "    except FileNotFoundError:\n",
    "        os.mkdir(bucket_path + path)\n",
    "        file = open(bucket_path + path + fname, write_method)\n",
    "    print('Saving', fname)\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "\n",
    "def get_grouped_ds(symbol, dataset):\n",
    "    # bulks download of all description modules\n",
    "    # can be streamlined to avoid request information that does not change often\n",
    "    key, value = query_map[dataset][enc_key], query_map[dataset][enc_val]\n",
    "    encoded_kv = urllib.parse.urlencode({key: value})\n",
    "    data = get_data(symbol, dataset, encoded_kv)\n",
    "    full_data = getChildrenList(json.loads(data), 'quoteSummary')\n",
    "    data = json.dumps(full_data)\n",
    "    path = get_storage_path(dataset).format(str(date.today()))\n",
    "    save_to_file(data, path, fname.format(symbol))\n",
    "\n",
    "def get_cs_tickers(ticker_list):\n",
    "    cs_tickers = ticker_list[0]\n",
    "    if len(ticker_list) > 1:\n",
    "        for t in ticker_list[1:]: cs_tickers = comma_join(cs_tickers, t)\n",
    "    return cs_tickers\n",
    "    \n",
    "def get_quotes(symbol_list):\n",
    "    dataset = 'quote'\n",
    "    full_data = []\n",
    "    index, max_elems = 0, MAX_SYMBOLS\n",
    "    for q in range(int(len(symbol_list) / max_elems) + 1):\n",
    "        subset = symbol_list[index:index + max_elems]\n",
    "        index += max_elems\n",
    "        symbols = get_cs_tickers(subset)\n",
    "        encoded_kv = urllib.parse.urlencode({query_map[dataset][enc_key]: symbols})\n",
    "        data = get_data(encoded_kv, dataset, '')\n",
    "        full_data.extend(getChildrenList(json.loads(data), 'quoteResponse'))\n",
    "    data = json.dumps(full_data)\n",
    "    save_to_file(data, get_storage_path(dataset), fname.format(str(date.today())))    \n",
    "    \n",
    "def get_options(symbol):\n",
    "    # save all options expirations dates to files for a given company\n",
    "    dataset = 'option'\n",
    "    print('Getting options expirations for', symbol)\n",
    "    key = query_map[dataset][enc_key]\n",
    "    encoded_kv = urllib.parse.urlencode({key: 0})\n",
    "    data = get_data(symbol, dataset, encoded_kv) # first expiration no date\n",
    "    json_dict = json.loads(data)\n",
    "    option_chain = json_dict['optionChain']['result'][0]\n",
    "    exp_dates = option_chain['expirationDates']\n",
    "    today_date = str(date.today())\n",
    "    full_data = []\n",
    "    for ed in exp_dates:\n",
    "        encoded_kv = urllib.parse.urlencode({query_map[dataset][enc_key]: ed})\n",
    "        data = get_data(symbol, dataset, encoded_kv)\n",
    "        full_data.extend(getChildrenList(json.loads(data), 'optionChain'))\n",
    "    data = json.dumps(full_data)\n",
    "    path = get_storage_path(dataset)\n",
    "    save_to_file(data, path.format(today_date), fname.format(symbol))\n",
    "\n",
    "def get_storage_path(dataset):\n",
    "    return config[dataset + '_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary/2018-09-11/FB.json\n",
      "CPU times: user 46.5 ms, sys: 11.8 ms, total: 58.3 ms\n",
      "Wall time: 4.3 s\n"
     ]
    }
   ],
   "source": [
    "%time get_grouped_ds('FB', 'summary')\n",
    "# %time get_quotes(['FB'])\n",
    "# %time get_options('FB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time for t in UNIVERSE: get_grouped_ds(t, 'summary')\n",
    "# %time get_quotes(UNIVERSE)\n",
    "# %time for t in UNIVERSE: get_options(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 storage scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_s3():\n",
    "    files = !find {BUCKET_NAME} | grep .json\n",
    "    local_files = [f[f.find('/') + 1:] for f in files ]\n",
    "    s3_objs = [x.key for x in bucket.objects.all()]\n",
    "    missing_s3 = set(local_files).difference(set(s3_objs))\n",
    "    print('Missing in S3 {0}, in S3 {1}'.format(len(missing_s3), len(local_files) - len(missing_s3)))\n",
    "    for file_key in list(missing_s3):\n",
    "        rootpath = './' + BUCKET_NAME + '/'\n",
    "        data = open(rootpath + file_key, 'rb')\n",
    "        print('Putting', file_key)\n",
    "        bucket.put_object(Body=data, Key=file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing in S3 0, in S3 793\n"
     ]
    }
   ],
   "source": [
    "# update_s3()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
