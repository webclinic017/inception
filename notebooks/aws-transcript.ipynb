{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config.json\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from basic_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading transcripts/affirm_seven_samurai.json\n"
     ]
    }
   ],
   "source": [
    "name = \"transcripts/affirm_seven_samurai\"\n",
    "results = load_config(name + '.json')\n",
    "results = results['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['transcripts', 'speaker_labels', 'items'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     30,
     36
    ]
   },
   "outputs": [],
   "source": [
    "def parse_detected_entities_response(detected_entities_response, entities):\n",
    "    if 'ErrorList' in detected_entities_response and len(detected_entities_response['ErrorList']) > 0:\n",
    "        logger.error(\"encountered error during batch_detect_entities\")\n",
    "        logger.error(\"error:\" + json.dumps(detected_entities_response['ErrorList'], indent=4))\n",
    "\n",
    "    if 'ResultList' in detected_entities_response:\n",
    "        result_list = detected_entities_response[\"ResultList\"]\n",
    "        # entities = {}\n",
    "        for result in result_list:\n",
    "            detected_entities = result[\"Entities\"]\n",
    "            for detected_entity in detected_entities:\n",
    "                if float(detected_entity[\"Score\"]) >= ENTITY_CONFIDENCE_THRESHOLD:\n",
    "\n",
    "                    entity_type = detected_entity[\"Type\"]\n",
    "\n",
    "                    if entity_type != 'QUANTITY':\n",
    "                        text = detected_entity[\"Text\"]\n",
    "\n",
    "                        if entity_type == 'LOCATION' or entity_type == 'PERSON' or entity_type == 'ORGANIZATION':\n",
    "                            if not text.isupper():\n",
    "                                text = string.capwords(text)\n",
    "\n",
    "                        if entity_type in entities:\n",
    "                            entities[entity_type].add(text)\n",
    "                        else:\n",
    "                            entities[entity_type] = set([text])\n",
    "        return entities\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def get_speaker_label(speaker_segments, start_time):\n",
    "    for segment in speaker_segments:\n",
    "        if segment['start_time'] <= start_time < segment['end_time']:\n",
    "            return segment['speaker']\n",
    "    return None\n",
    "\n",
    "def parse_speaker_segments(results):\n",
    "    speaker_labels = results['speaker_labels']['segments']\n",
    "    speaker_segments = []\n",
    "    for label in speaker_labels:\n",
    "        segment = dict()\n",
    "        segment[\"start_time\"] = float(label[\"start_time\"])\n",
    "        segment[\"end_time\"] = float(label[\"end_time\"])\n",
    "        segment[\"speaker\"] = label[\"speaker_label\"]\n",
    "        speaker_segments.append(segment)\n",
    "    return speaker_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_label_exist = False\n",
    "speaker_segments = None\n",
    "if 'speaker_labels' in results:\n",
    "    speaker_label_exist = True\n",
    "    speaker_segments = parse_speaker_segments(results)\n",
    "# speaker_label_exist, speaker_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "items = results['items']\n",
    "last_speaker = None\n",
    "paragraphs = []\n",
    "current_paragraph = \"\"\n",
    "comprehend_chunks = []\n",
    "current_comprehend_chunk = \"\"\n",
    "previous_time = 0\n",
    "last_pause = 0\n",
    "last_item_was_sentence_end = False\n",
    "commonDict = {'i': 'I'}\n",
    "custom_vocabs = None\n",
    "\n",
    "for item in items:\n",
    "    if item[\"type\"] == \"pronunciation\":\n",
    "        start_time = float(item['start_time'])\n",
    "\n",
    "        if speaker_label_exist:\n",
    "            current_speaker = get_speaker_label(\n",
    "                speaker_segments, float(item['start_time']))\n",
    "            if last_speaker is None or current_speaker != last_speaker:\n",
    "                if current_paragraph is not None:\n",
    "                    paragraphs.append(current_paragraph)\n",
    "                current_paragraph = current_speaker + \\\n",
    "                \" ({}m:{}s)\".format(\n",
    "                    round(start_time//60),\n",
    "                    round((start_time/60-start_time//60) * 60))\n",
    "                last_pause = start_time\n",
    "            last_speaker = current_speaker\n",
    "\n",
    "        elif (start_time - previous_time) > 2 or (\n",
    "                        (start_time - last_pause) > 15 and last_item_was_sentence_end):\n",
    "            last_pause = start_time\n",
    "            if current_paragraph is not None or current_paragraph != \"\":\n",
    "                paragraphs.append(current_paragraph)\n",
    "            current_paragraph = \"\"\n",
    "\n",
    "        phrase = item['alternatives'][0]['content']\n",
    "        if custom_vocabs is not None:\n",
    "            if phrase in custom_vocabs:\n",
    "                phrase = custom_vocabs[phrase]\n",
    "                logger.info(\"replaced custom vocab: \" + phrase)\n",
    "        if phrase in commonDict:\n",
    "            phrase = commonDict[phrase]\n",
    "        current_paragraph += \" \" + phrase\n",
    "\n",
    "        # add chunking\n",
    "        current_comprehend_chunk += \" \" + phrase\n",
    "\n",
    "        last_item_was_sentence_end = False\n",
    "\n",
    "    elif item[\"type\"] == \"punctuation\":\n",
    "        current_paragraph += item['alternatives'][0]['content']\n",
    "        current_comprehend_chunk += item['alternatives'][0]['content']\n",
    "        if item['alternatives'][0]['content'] in (\".\", \"!\", \"?\"):\n",
    "            last_item_was_sentence_end = True\n",
    "        else:\n",
    "            last_item_was_sentence_end = False\n",
    "\n",
    "    if (item[\"type\"] == \"punctuation\" and len(current_comprehend_chunk) >= 4500) \\\n",
    "            or len(current_comprehend_chunk) > 4900:\n",
    "        comprehend_chunks.append(current_comprehend_chunk)\n",
    "        current_comprehend_chunk = \"\"\n",
    "\n",
    "    if 'end_time' in item:\n",
    "        previous_time = float(item['end_time'])\n",
    "\n",
    "if not current_comprehend_chunk == \"\":\n",
    "    comprehend_chunks.append(current_comprehend_chunk)\n",
    "if not current_paragraph == \"\":\n",
    "    paragraphs.append(current_paragraph)\n",
    "# print(\"\\n\\n\".join(paragraphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(name + '.html', mode='w') as f:\n",
    "    f.write(\"<h2>\"+ name + \"</h2>\")\n",
    "    f.write(\"<br/><br/>\".join(paragraphs))\n",
    "#     for s in sorted_symbols:\n",
    "#         f.write(p2[p2.symbol == s][brief_cols].T.to_html())\n",
    "#         f.write('<p style=\"page-break-before: always\">')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
