{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.basic_utils import *\n",
    "from utils.pricing import *\n",
    "from utils import ml_utils as mu\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, sys\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, log_loss, precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score, roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench = '^GSPC'\n",
    "sec_windows, stds = [5, 20, 60], 1\n",
    "pred_fwd_windows = [60]\n",
    "inv = incl_px = incl_name = False\n",
    "y_col = 'fwdReturn'\n",
    "cuts = { '1d': [-1, -0.1, -.02, .02, .1, 1.] }\n",
    "cut_range = cuts['1d']\n",
    "fwd_ret_labels = [\"bear\", \"short\", \"neutral\", \"long\", \"bull\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pricing / context data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TAKES ~8m on local drive, 3m on AWS for 1230 companies, do once and persist\n",
    "excl_list = [] # ['BHF', 'ERI']\n",
    "symbols_list = excl(config['companies'], excl_list)\n",
    "px_close = get_mults_pricing(symbols_list).drop_duplicates().dropna(subset=['AAPL'])\n",
    "# save down to drive if refresh pricing\n",
    "os.makedirs('tmp', exist_ok=True)\n",
    "px_close.to_parquet('tmp/mult-co-px-ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px_close = pd.read_parquet('tmp/mult-co-px-ds')\n",
    "px_close.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px_close.tail().isna().any(0).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest quotes, profile, and industries\n",
    "dates = read_dates('quote')\n",
    "tgt_date = [dates[-1]] # last date saved in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "quotes = load_csvs('quote_consol', tgt_date)\n",
    "quotes.set_index('symbol', drop=False, inplace=True)\n",
    "\n",
    "profile = load_csvs('summary_detail', ['assetProfile'])\n",
    "profile.set_index('symbol', drop=False, inplace=True)\n",
    "\n",
    "profile.drop(profile[profile.symbol.isin(excl_list)].index, inplace=True)\n",
    "\n",
    "all_equities = quotes[quotes.quoteType == 'EQUITY'].symbol.unique()\n",
    "print('Delta quote: ', set(symbols_list) - set(all_equities))\n",
    "# reduced subset, if any\n",
    "sub_equities = set(px_close.columns.tolist()).intersection(all_equities)\n",
    "print('Delta reduced set: ', set(symbols_list) - set(sub_equities))\n",
    "\n",
    "eqty_symbols = profile[profile.symbol.isin(sub_equities)].symbol.unique().tolist()\n",
    "delta_symb = set(symbols_list) - set(eqty_symbols)\n",
    "print('Delta profile: ', len(delta_symb), delta_symb)\n",
    "\n",
    "# Create a frame of market, sector and industry index (once)\n",
    "# for relative performance calculations\n",
    "sel_profiles = profile[profile.symbol.isin(all_equities)]\n",
    "sel_profiles.groupby(['sector', 'industry'])[['industry']].count()\n",
    "sectors = sel_profiles.sector.unique()\n",
    "industries = sel_profiles.industry.unique()\n",
    "\n",
    "print(f'Sectors: {sectors.shape[0]}, Industries: {industries.shape[0]}')\n",
    "\n",
    "indices_df = pd.concat([\n",
    "    eq_wgt_indices(profile, px_close, 'sector', sectors, subset=eqty_symbols),\n",
    "    eq_wgt_indices(profile, px_close, 'industry', industries, subset=eqty_symbols),\n",
    "    to_index_form(get_symbol_pricing(bench)['close'], bench)\n",
    "], axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     86,
     154
    ]
   },
   "outputs": [],
   "source": [
    "def create_ds(context):\n",
    "    print('create_ds')\n",
    "    train_model = context['train_model']\n",
    "    (path, ds_name) = context['ds_path_name']\n",
    "    tickers = context['tickers']\n",
    "    load_ds = context['load_ds']\n",
    "    tail = 10**4 if train_model else 252*2\n",
    "\n",
    "    if load_ds & os.path.isfile(path + '/' + ds_name):\n",
    "        df_large = pd.read_parquet(path + '/' + ds_name)\n",
    "        return df_large\n",
    "    \n",
    "    super_list = []\n",
    "    for i, ticker in tqdm(enumerate(tickers)):\n",
    "        try:\n",
    "            close = px_close[ticker].dropna().tail(tail)\n",
    "            ft_df = px_mom_feats(close, ticker, stds, inv, incl_px, sec_windows, incl_name)\n",
    "            ft_df[y_col] = px_fwd_rets(close, ticker, pred_fwd_windows).mean(axis=1)\n",
    "\n",
    "            df = get_symbol_pricing(ticker).tail(tail) #full retrieve\n",
    "            top_groups = tuple([bench] + list(profile.loc[ticker, ['sector', 'industry']]))\n",
    "            co = px_mom_co_feats(df, indices_df, top_groups)\n",
    "\n",
    "            ft_df.loc[:, 'country'] = profile.loc[ticker,:].country\n",
    "            ft_df.loc[:, 'currency'] = quotes.loc[ticker,:].currency\n",
    "            ft_df = pd.concat([ft_df, co.loc[ft_df.index, :]], axis=1)\n",
    "            super_list.append(ft_df)\n",
    "            # print('{} Adding {} to dataset'.format(i, ticker))\n",
    "        except Exception as e:\n",
    "            print(\"Exception: {0}\\n{1}\".format(ticker, e))\n",
    "    df_large = pd.concat(super_list, axis=0)\n",
    "    \n",
    "    if train_model:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        df_large.to_parquet(path + '/' + ds_name)\n",
    "    print('df_large.shape {}'.format(df_large.shape))\n",
    "    \n",
    "    return df_large\n",
    "\n",
    "def pre_process_ds(raw_df, context):\n",
    "    print('pre_process_ds')    \n",
    "    train_model = context['train_model']\n",
    "    fill_on, imputer_on, scaler_on = context['fill'], context['impute'], context['scale']\n",
    "    categoricals, exclude = context['categoricals'], context['exclude']\n",
    "    (path, train_cols) = context['trained_cols']\n",
    "    test_sz, verbose = context['test_size'], context['verbose']\n",
    "    \n",
    "    # convert categorical columns    \n",
    "    for col in categoricals: raw_df = dummy_col(raw_df, col, shorten=True)\n",
    "    raw_df.drop(columns=exclude[:-1], inplace=True) # remove all except symbol\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    imputer = SimpleImputer(\n",
    "        missing_values=np.nan, \n",
    "        strategy='median', copy=False)\n",
    "    X_cols = excl(raw_df.columns, [exclude[-1] ,y_col]) #not needed\n",
    "        \n",
    "    raw_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    if scaler_on: raw_df.loc[:, X_cols] = scaler.fit_transform(raw_df[X_cols])\n",
    "\n",
    "    pred_X = X_train = X_test = y_train = y_test = None\n",
    "    if train_model:\n",
    "        raw_df.drop(columns=exclude[-1], inplace=True) # remove symbol\n",
    "        if fill_on: raw_df.loc[:, X_cols].fillna(method=fill_on, inplace=True)\n",
    "\n",
    "        # discretize forward returns into classes\n",
    "        raw_df.dropna(subset=[y_col], inplace=True)\n",
    "        raw_df.loc[:, y_col] = discret_rets(raw_df[y_col], cut_range, fwd_ret_labels)\n",
    "        raw_df.dropna(subset=[y_col], inplace=True) # no nas in y_col\n",
    "        print(sample_wgts(raw_df[y_col]))\n",
    "        raw_df.loc[:, y_col] = raw_df[y_col].astype(str) # class as string\n",
    "        \n",
    "        if imputer_on: raw_df.loc[:, X_cols] = imputer.fit_transform(raw_df[X_cols])\n",
    "        else: raw_df = raw_df.dropna()\n",
    "\n",
    "        X, y = raw_df.drop(columns=y_col), raw_df[y_col]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_sz, random_state=42)\n",
    "        np.save(path + train_cols, X_train.columns) # save feature order\n",
    "    else: \n",
    "        # feature for last date, pending to implement more flexibility\n",
    "        pred_X = raw_df.loc[raw_df.index[-1], :].drop(columns=y_col).dropna(axis=0)\n",
    "    \n",
    "    [print(x.shape) for x in (pred_X, X_train, X_test, y_train, y_test) if x is not None]\n",
    "    return pred_X, X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_ds(context):\n",
    "    context['load_ds'] = True\n",
    "    context['train_model'] = True\n",
    "    grid_search = context['grid_search']\n",
    "    verbose = context['verbose']\n",
    "    (path, model_name) = context['ml_path']\n",
    "    portion = context['portion']\n",
    "        \n",
    "    ds_df = create_ds(context)\n",
    "    print(df.info(verbose=False))\n",
    "    _, X_train, X_test, y_train, y_test = pre_process_ds(ds_df, context)\n",
    "\n",
    "    features = X_train.shape[1]\n",
    "    best_params = { # best from GridSearch\n",
    "        'n_estimators': 25, \n",
    "        'max_features': features, \n",
    "        'max_depth': 30,\n",
    "        'min_samples_split': 2,\n",
    "        'min_samples_leaf': 2,\n",
    "        'random_state': 0,    \n",
    "        'n_jobs': -1}\n",
    "    if grid_search:\n",
    "        print('GridSearchCV for RandomForestClassifier')\n",
    "        param_grid = {\n",
    "            'n_estimators': [50], \n",
    "            'max_features': ['sqrt', 'log2', features // 2, features // 3,], \n",
    "            'max_depth': [30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [2, 5, 10],\n",
    "            'random_state': np.arange(0, 3, 1),}\n",
    "        clf = GridSearchCV(RandomForestClassifier(random_state=42),\n",
    "                           param_grid, n_jobs=-1,\n",
    "                           cv=5, iid=True, verbose=verbose)\n",
    "        clf.fit(X_train, y_train)\n",
    "        if verbose: \n",
    "            mu.print_cv_results(\n",
    "                clf, (X_train, X_test, y_train, y_test), \n",
    "                feat_imp=True, top=20)\n",
    "        best_params = clf.best_params_\n",
    "    clf1 = RandomForestClassifier(**best_params)\n",
    "    clf1.fit(X_train, y_train)\n",
    "    print('RandomForestClassifier scores: Train {}, Test {}'.format(\n",
    "    clf1.score(X_train, y_train), clf1.score(X_test, y_test)))\n",
    "    \n",
    "    # ExtraTreesClassifier\n",
    "    clf2 = ExtraTreesClassifier(\n",
    "        n_estimators=50, \n",
    "        max_depth=30, \n",
    "        min_samples_split=2, \n",
    "        min_samples_leaf=1,        \n",
    "        random_state=5, \n",
    "        n_jobs=-1)\n",
    "    clf2.fit(X_train, y_train)\n",
    "    print('ExtraTreesClassifier scores: Train {}, Test {}'.format(\n",
    "    clf2.score(X_train, y_train), clf2.score(X_test, y_test)))\n",
    "                \n",
    "    for vote in ['hard', 'soft']:\n",
    "        eclf = VotingClassifier(\n",
    "            estimators=[('rf', clf1), ('et', clf2)],\n",
    "            voting=vote)\n",
    "        clf = eclf.fit(X_train, y_train)\n",
    "        print('VotingClassifier scores Train {}, Test {}'.format(\n",
    "                clf.score(X_train, y_train), clf.score(X_test, y_test)))\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        fname = path + model_name.format(vote)\n",
    "        joblib.dump(clf, fname)\n",
    "        print('Saved ', fname)\n",
    "        \n",
    "def predict_ds(context):\n",
    "    context['load_ds'] = False\n",
    "    context['train_model'] = False\n",
    "    (path, model_name) = context['ml_path']\n",
    "    verbose = context['verbose']\n",
    "    (path, train_cols) = context['trained_cols']\n",
    "    \n",
    "    df_large = create_ds(context)\n",
    "    pred_X, _, _, _, _ = pre_process_ds(df_large, context)\n",
    "    print('predict_ds')\n",
    "    print('pred_X.shape', pred_X.shape)\n",
    "    \n",
    "    # ensure prediction dataset is consistent with trained model\n",
    "    trained_cols = np.load(path + train_cols) # save feature order    \n",
    "    missing_cols = [x for x in trained_cols if x not in pred_X.columns]\n",
    "    pred_X = pd.concat([pred_X, pd.DataFrame(columns=missing_cols)], axis=1)\n",
    "    pred_X[missing_cols] = 0\n",
    "    pred_X = pred_X[list(trained_cols) + ['symbol']]    \n",
    "\n",
    "    pred_df = pd.DataFrame()\n",
    "    pred_df['symbol'] = pred_X.symbol\n",
    "    for vote in ['hard', 'soft']:\n",
    "        fname = path + model_name.format(vote)\n",
    "        clf = joblib.load(fname) # load latest models\n",
    "        print('Loaded', fname)\n",
    "        preds = clf.predict(pred_X.iloc[:, :-1])\n",
    "        # preds = np.where(preds == 'nan', 'neutral', preds) #replace nan\n",
    "        pred_class = np.array([fwd_ret_labels.index(x) for x in preds])        \n",
    "        pred_df[f'{vote}_pred_class'] = pred_class\n",
    "        pred_df[f'{vote}_pred_label'] = preds\n",
    "        if vote == 'soft':\n",
    "            probs = clf.predict_proba(pred_X.iloc[:, :-1])\n",
    "            pred_prob = np.argmax(probs, axis=1)\n",
    "            pred_df[f'{vote}_confidence'] = [x[np.argmax(x)] for x in probs] # higest prob\n",
    "            prob_df = pd.DataFrame(probs, index=pred_df.index, columns=clf.classes_)\n",
    "            pred_df = pd.concat([pred_df, prob_df[fwd_ret_labels]], axis=1)\n",
    "\n",
    "    # store in S3\n",
    "    s3_path = context['s3_path']\n",
    "    s3_df = pred_df.reset_index(drop=False)\n",
    "    rename_col(s3_df, 'index', 'pred_date')\n",
    "    csv_store(s3_df, s3_path, csv_ext.format(dates[-1]))\n",
    "            \n",
    "    return pred_df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# pending cleanup: use ml_path and tmp_path separate\n",
    "context = {\n",
    "    'tickers': [],\n",
    "    'ml_path': ('../ML/', 'co_pxmom_ML_{}.pkl'),\n",
    "    'ds_path_name': ('tmp', 'co-pxmom-large'),\n",
    "    'trained_cols': ('../ML/', 'co_pxmom_train_cols.npy'),\n",
    "    'load_ds': True,\n",
    "    'portion': 100e-2,\n",
    "    'categoricals': ['sector'],\n",
    "    'exclude': ['industry', 'country', 'currency', 'symbol'],\n",
    "    'fill': 'bfill',\n",
    "    'impute': False,\n",
    "    'scale': True,\n",
    "    'test_size': .20,\n",
    "    'grid_search': False,\n",
    "    'verbose': 2,\n",
    "    's3_path': 'recommend/co-pxmom/'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!rm ./tmp/{context['ds_path_name'][1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time train_ds(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(path, _) = context['ml_path']\n",
    "!ls -lh ./{path}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predict for all\n",
    "context['tickers'] = eqty_symbols[:50]\n",
    "%time pred_df = predict_ds(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store / Read S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = context['s3_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storeDate = dates[-1]\n",
    "# storeDate = '2019-03-27'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from S3\n",
    "pred_df = pd.read_csv(\n",
    "    csv_load(f'{s3_path}{storeDate}'), \n",
    "    index_col='pred_date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store in S3\n",
    "s3_df = pred_df.reset_index(drop=False)\n",
    "rename_col(s3_df, 'index', 'pred_date')\n",
    "csv_store(s3_df, s3_path, csv_ext.format(storeDate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommendation distribution\n",
    "pd.value_counts(pred_df.loc[pred_df.hard_pred_label == pred_df.soft_pred_label].soft_pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 3 picks by label\n",
    "mask = pred_df.hard_pred_label == pred_df.soft_pred_label\n",
    "agree_df = pred_df.loc[mask].drop_duplicates()\n",
    "# should add sector and industries, group for allocation insights\n",
    "# should add marketcap, beta, etc, group for risk exposure insights\n",
    "label_mask = agree_df.soft_pred_label.isin(['bear', 'short', 'long', 'bull'])\n",
    "agree_df.loc[label_mask]\\\n",
    "    .sort_values(by='soft_confidence', ascending=False)\\\n",
    "    .groupby(by='soft_pred_label').head(5)\\\n",
    "    .sort_values(by='soft_pred_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.loc[pred_df.symbol == 'BIIB',:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Take a while ~40min to run on 1200 companies\n",
    "# Can we make faster?\n",
    "super_list = []\n",
    "for i, ticker in enumerate(tickers):\n",
    "    try:\n",
    "        close = px_close[ticker].drop_duplicates()\n",
    "        ft_df = px_mom_feats(\n",
    "            close, ticker, stds, inv, incl_px, \n",
    "            sec_windows, incl_name)\n",
    "        ft_df[y_col] = px_fwd_rets(\n",
    "            close, ticker, pred_fwd_windows).mean(axis=1)\n",
    "        df = get_symbol_pricing(ticker) #full retrieve\n",
    "        co = px_mom_co_feats(\n",
    "            df, indices_df, \n",
    "            [bench] + list(profile.loc[ticker, ['sector', 'industry']]))\n",
    "\n",
    "        ft_df.loc[:, 'country'] = profile.loc[ticker,:].country\n",
    "        ft_df.loc[:, 'currency'] = quotes.loc[ticker,:].currency\n",
    "\n",
    "        ft_df = pd.concat([ft_df.dropna(), co.dropna()], axis=1)\n",
    "        super_list.append(ft_df)\n",
    "        print(i, ticker)\n",
    "    except Exception as e:\n",
    "        print(\"Exception: {0}\\n{1}\".format(ticker, e))\n",
    "df_large = pd.concat(super_list, axis=0)\n",
    "os.makedirs('tmp', exist_ok=True)\n",
    "df_large.to_parquet('tmp/company-px_mom-large')\n",
    "df_large.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_large = pd.read_parquet('tmp/company-px_mom-large')\n",
    "print(df_large.info(verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_large = trim_df(df_large, context['portion'])\n",
    "df_large.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "categoricals = context['categoricals']\n",
    "exclude = context['exclude']\n",
    "for col in categoricals: df_large = dummy_col(df_large, col, shorten=True)\n",
    "df_large.drop(columns=exclude, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%time pred_X, X_train, X_test, y_train, y_test = pre_process_ds(df_large, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[x.shape for x in (X_train, X_test, y_train, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Trims dataset in case it's too large for experimentation\n",
    "# Reduce dataset for experimentation\n",
    "# Note that experiment dataset is not stratified\n",
    "exp_perc = 20e-2\n",
    "_, df_raw = train_test_split(df_large, test_size=exp_perc, shuffle=True, )\n",
    "\n",
    "df_raw.dropna(subset=[y_col],  inplace=True)\n",
    "df_raw[y_col] = discret_rets(df_raw[y_col], cut_range, fwd_ret_labels)\n",
    "\n",
    "# df_raw.loc[:, y_col] = df_raw[y_col].astype(str)\n",
    "\n",
    "y_col_dist = sample_wgts(df_raw[y_col], fwd_ret_labels)\n",
    "(y_col_dist[fwd_ret_labels]).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "categoricals = ['sector', 'industry', 'country', 'currency']\n",
    "%time for col in categoricals: df_raw = dummy_col(df_raw, col, shorten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "excl_list = ['symbol', ] # drop unneeded columns\n",
    "%time df_raw.drop(columns=excl_list, inplace=True, errors='ignore')\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Mean based imputer\n",
    "imputer_on, scaler_on = True, False\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean', copy=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pre_ml_df = df_raw.copy()\n",
    "pre_ml_df.dropna(subset=[y_col], inplace=True)\n",
    "pre_ml_df.loc[:, y_col] = pre_ml_df[y_col].astype(str)\n",
    "X_cols = excl(pre_ml_df.columns, [y_col])\n",
    "\n",
    "if imputer_on: pre_ml_df.loc[:, X_cols] = imputer.fit_transform(pre_ml_df[X_cols])\n",
    "else: pre_ml_df.dropna(inplace=True)\n",
    "if scaler_on: pre_ml_df.loc[:, X_cols] = scaler.fit_transform(pre_ml_df[X_cols])\n",
    "\n",
    "X, y = pre_ml_df.drop(columns=y_col), pre_ml_df[y_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "grid_search = context['grid_search']\n",
    "verbose = context['verbose']\n",
    "best_params = {\n",
    "    'n_estimators': 100, \n",
    "    'max_features': X_train.shape[1] // 2, \n",
    "    'random_state': 0,\n",
    "    'max_depth': None, \n",
    "    'min_samples_split': 2, \n",
    "    'n_jobs': -1}\n",
    "if grid_search:\n",
    "    print('GridSearchCV for RandomForestClassifier')\n",
    "    param_grid = {\n",
    "        'n_estimators': [100], \n",
    "        'max_features': ['sqrt', X_train.shape[1] // 2, X_train.shape[1] // 3,],\n",
    "        'random_state': np.arange(0, 5, 1),}\n",
    "    clf = GridSearchCV(RandomForestClassifier(random_state=42),\n",
    "                       param_grid, n_jobs=-1,\n",
    "                       cv=5, iid=True, verbose=verbose)\n",
    "    clf.fit(X_train, y_train)\n",
    "    if verbose: print_cv_results(clf, X_train, X_test, y_train, y_test, feat_imp=True, top=20)\n",
    "    best_params = clf.best_params_\n",
    "clf1 = RandomForestClassifier(**best_params)\n",
    "%time clf1.fit(X_train, y_train)\n",
    "print('RandomForestClassifier scores: Train {}, Test {}'.format(\n",
    "clf1.score(X_train, y_train), clf1.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ExtraTreesClassifier\n",
    "clf2 = ExtraTreesClassifier(\n",
    "    n_estimators=100, max_depth=None, \n",
    "    min_samples_split=2, random_state=0, n_jobs=-1)\n",
    "\n",
    "%time clf2.fit(X_train, y_train)\n",
    "print('ExtraTreesClassifier scores: Train {}, Test {}'.format(\n",
    "clf2.score(X_train, y_train), clf2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# MLPClassifier\n",
    "params = {\n",
    "    'activation': 'relu', \n",
    "    'alpha': 0.001, \n",
    "    'hidden_layer_sizes': (50,), \n",
    "    'learning_rate': 'adaptive', \n",
    "    'max_iter': 200, \n",
    "    'random_state': 3, \n",
    "    'solver': 'adam'}\n",
    "\n",
    "clf3 = MLPClassifier(**params)\n",
    "\n",
    "clf3.fit(X_train, y_train)\n",
    "print('MLPClassifier scores: Train {}, Test {}'.format(\n",
    "clf3.score(X_train, y_train), clf3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ml_path = context['ml_path']\n",
    "for vote in ['hard', 'soft']:\n",
    "    eclf = VotingClassifier(\n",
    "        estimators=[('rf', clf1), ('et', clf2)],\n",
    "        voting=vote)\n",
    "    clf = eclf.fit(X_train, y_train)\n",
    "    print('VotingClassifier scores Train {}, Test {}'.format(\n",
    "            clf.score(X_train, y_train), clf.score(X_test, y_test)))\n",
    "    os.makedirs(ml_path, exist_ok=True)\n",
    "    fname = ml_path + f'co_pxmom_ML_{vote}.pkl'\n",
    "    joblib.dump(clf, fname)\n",
    "    print('Saved ', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def predict_ds(context):\n",
    "    ml_path = context['ml_path']\n",
    "    verbose = context['verbose']\n",
    "    \n",
    "    px_close = get_mults_pricing(include, freq, verbose=verbose);\n",
    "    px_close.drop_duplicates(inplace=True)\n",
    "    \n",
    "    ds_idx, df_large = create_ds(px_close, context)\n",
    "    pred_X, _, _, _, _ = pre_process_ds(df_large, context)    \n",
    "\n",
    "    print('pred_X.shape', pred_X.shape)\n",
    "\n",
    "    bench_df = px_close.loc[pred_X.index, bench].to_frame()\n",
    "    for vote in ['hard', 'soft']:\n",
    "        fname = ml_path + f'macro_ML_{vote}.pkl'\n",
    "        clf = joblib.load(fname) # load latest models\n",
    "        print('Loaded', fname)\n",
    "        preds = clf.predict(pred_X)\n",
    "        pred_class = np.array([fwd_ret_labels.index(x) for x in preds])        \n",
    "        bench_df[f'{vote}_pred_class'] = pred_class\n",
    "        bench_df[f'{vote}_pred_label'] = preds\n",
    "        if vote == 'soft':\n",
    "            probs = clf.predict_proba(pred_X)\n",
    "            pred_prob = np.argmax(probs, axis=1)\n",
    "            bench_df[f'{vote}_confidence'] = [x[np.argmax(x)] for x in probs] # higest prob\n",
    "            prob_df = pd.DataFrame(probs, index=bench_df.index, columns=clf.classes_)\n",
    "            bench_df = pd.concat([bench_df, prob_df[fwd_ret_labels]], axis=1)\n",
    "        bench_df.dropna(subset=[bench], inplace=True)\n",
    "\n",
    "    return bench_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "show_fi(clf1, X_train, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Confussion Matrix\\n', confusion_matrix(clf.predict(X_test), y_test, labels=fwd_ret_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Classificaton report\\n', classification_report(clf.predict(X_test), y_test, target_names=fwd_ret_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_loss(y_test, clf.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Gridsearches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.arange(10, X.shape[1], int(X.shape[1]*.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# GridSearchCV for RandomForestClassifier\n",
    "parameters = {\n",
    "    'n_estimators': [10, 20, 40], \n",
    "    'max_features': np.arange(10, X.shape[1], int(X.shape[1]*.25)), \n",
    "    'random_state': np.arange(1, 10, 3)}\n",
    "\n",
    "# parameters = {\n",
    "#     'n_estimators': [80], \n",
    "#     'max_features': [16], \n",
    "#     'random_state': [4]}\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), parameters, n_jobs=-1, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_train, y_train), clf.score(X_test, y_test))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Feature construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = get_symbol_pricing(ticker)\n",
    "ft_df = px_mom_feats(df, ticker, stds, inv, incl_px, sec_windows, incl_name)\n",
    "ft_df[y_col] = px_fwd_rets(\n",
    "    df.close, ticker, pred_fwd_windows).mean(axis=1, skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display_all(ft_df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Y = px_fwd_rets(df.close, ticker, pred_fwd_windows)\n",
    "Y.mean(axis=1).plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "px_close[ticker].shape, px.close.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "px_close[ticker].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = px_close[[ticker]].copy()\n",
    "# df.set_index(df.index.astype(np.datetime64), inplace=True)\n",
    "df.loc[:, 'weekday'] = df.index.weekday\n",
    "df.weekday.unique()\n",
    "df.tail(60)\n",
    "df.groupby('weekday').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = get_symbol_pricing(ticker)\n",
    "co = px_mom_co_feats(\n",
    "    df, indices_df, \n",
    "    [bench] + list(profile.loc[ticker, ['sector', 'industry']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "co.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Date and minute based time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freq = '1d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# s1, s2 = '1810.HK', 'AAPL'\n",
    "group_pricing = pd.DataFrame()\n",
    "df1 = get_symbol_pricing(s1, freq, ['close'])\n",
    "df2 = get_symbol_pricing(s2, freq, ['close'])\n",
    "group_pricing = pd.DataFrame(df1)\n",
    "# group_pricing.loc[:, s2] = df2\n",
    "group_pricing = pd.concat([group_pricing, df2], axis=1)\n",
    "group_pricing.describe()\n",
    "# group_pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = config['pricing_path'].format(freq)\n",
    "data_dict = json_load(path + json_ext.format(ticker))\n",
    "\n",
    "tz = data_dict['meta']['exchangeTimezoneName']\n",
    "df = build_px_struct(data_dict, freq)\n",
    "\n",
    "adjClose = data_dict['indicators']['adjclose'][0] if 'adjclose' in  data_dict['indicators'] else 0\n",
    "close = data_dict['indicators']['quote'][0]\n",
    "data_dict.keys(), data_dict['indicators'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.index.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(\n",
    "        data_dict['timestamp'], \n",
    "        unit='s', infer_datetime_format=True)\n",
    "# dates = dates.astype(f'datetime64[ns, {tz}]')\n",
    "# dates.tz_convert('America/New_York')\n",
    "# dates = dates.tz_localize('America/New_York')\n",
    "dates.floor('d' if freq == '1d' else 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freq = '1d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%time px_close = get_mults_pricing(symbols_list[:10], freq);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# [px_close[x].dropna().tail() for x in px_close.columns]\n",
    "px_close.describe()\n",
    "# px_close.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f'Ticker: {ticker}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "px = get_symbol_pricing(ticker, freq)\n",
    "px.close.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test distribution of Y variable\n",
    "tickers = list(mu.sample_sector_tickers(eqty_symbols, profile, sectors, 50).index)\n",
    "context['grid_search'] = False\n",
    "context['tickers'] = tickers\n",
    "context['train_model'] = True\n",
    "\n",
    "df_large = create_ds(context)\n",
    "\n",
    "df = df_large.copy()\n",
    "df.dropna(subset=[y_col], inplace=True)\n",
    "df[y_col] = discret_rets(df[y_col], cut_range, fwd_ret_labels)\n",
    "df.dropna(subset=[y_col], inplace=True) # no nas in y_col\n",
    "df[y_col] = df[y_col].astype(str) # class as string\n",
    "sample_wgts(df[y_col])\n",
    "\n",
    "pred_X, X_traxin, X_test, y_train, y_test = pre_process_ds(df_large, context)\n",
    "pd.value_counts(discret_rets(df_large.fwdReturn, cut_range, fwd_ret_labels)).sum()\n",
    "pd.value_counts(pd.concat([y_train, y_test], axis=0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test cumulative drawdowns and pulls\n",
    "n = 100\n",
    "r_w = np.random.randn(n).cumsum() + 100\n",
    "l_dd, h_dd, l_p, h_p = max_draw_pull(r_w)\n",
    "\n",
    "plt.plot(r_w)\n",
    "plt.plot(\n",
    "    [l_dd, h_dd], \n",
    "    [r_w[l_dd], r_w[h_dd],], \n",
    "    'o', color='Red', markersize=10)\n",
    "plt.plot(\n",
    "    [l_p, h_p], \n",
    "    [r_w[l_p], r_w[h_p]], \n",
    "    'o', color='Green', markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Retrieves historical pricing\n",
    "secpx = get_symbol_pricing(symbol, freq)\n",
    "secpx.set_index(secpx.index.astype(np.datetime64), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fwd_ss_ret = lambda x, df, arr: df.loc[[y for y in arr[x-1] if y in df.index.tolist()]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# seasonality analysis\n",
    "ss_df = closepx.pct_change().resample('M').sum().to_frame()\n",
    "ss_df['year'], ss_df['month'] = ss_df.index.year, ss_df.index.month\n",
    "ss_df = ss_df.pivot_table(index='year', columns='month').mean()\n",
    "ss_pos = [(x, (x+1) if not (x+1) // 12 else 0, \n",
    "     x+2 if not (x+2) // 12 else x - 10) for x in range(12)]\n",
    "\n",
    "# [fwd_ss_ret(x+1, ss_df['close'], ss_pos) for x in range(12)] # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# apply seasonality, mean return of curr month plus next two\n",
    "secpx['month'] = secpx.index.month\n",
    "secpx['fwdSSRet'] = secpx.loc[:].month.apply(\n",
    "    fwd_ss_ret, args=(ss_df['close'], ss_pos,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "secpx.columns # all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# normalized columns for ML training, still has outliers\n",
    "ml_ds_cols = secpx.describe().loc['50%'][secpx.describe().loc['50%'] < 5].index.tolist()\n",
    "ml_ds_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# prepare ML dataset\n",
    "ml_ds = secpx[ml_ds_cols].copy()\n",
    "\n",
    "class_cols = ['fwdChg1w', 'fwdChg1m', 'fwdChg3m']\n",
    "cut_range = [-1, -0.05, .0, .02, .09, 1.]\n",
    "fwd_ret_labels = [\"bear\", \"short\", \"neutral\", \"long\", \"bull\"]\n",
    "\n",
    "for c in class_cols: ml_ds[c] = pd.cut(secpx[c], cut_range, labels=fwd_ret_labels)\n",
    "ml_ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# drop the predicting class with most nas\n",
    "ml_ds.dropna(inplace=True)\n",
    "ml_ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ml_ds.hist(figsize=(15,15));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ml_ds.to_csv(csv_ext.format('co_price_mom_ds'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
