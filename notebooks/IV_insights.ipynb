{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.basic_utils import *\n",
    "from utils.pricing import *\n",
    "import utils.fundamental as fu\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the latest saved data for profile and quote info\n",
    "dates = read_dates('quote')\n",
    "tgt_date = dates[-1] # last date saved in S3\n",
    "\n",
    "quotes = load_csvs('quote_consol', [tgt_date])\n",
    "quotes.set_index('symbol', drop=False, inplace=True)\n",
    "\n",
    "profile = load_csvs('summary_detail', ['assetProfile'])\n",
    "profile.set_index('symbol', drop=False, inplace=True)\n",
    "\n",
    "keystats = load_csvs('summary_detail', ['defaultKeyStatistics/' + str(tgt_date)])\n",
    "keystats.set_index('symbol', drop=False, inplace=True)\n",
    "finstats = load_csvs('summary_detail', ['financialData/' + str(tgt_date)])\n",
    "finstats.set_index('symbol', drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from S3\n",
    "val_df = pd.read_csv(csv_load(f'valuation/waterfall/{tgt_date}'), parse_dates=True)\n",
    "val_df.storeDate = pd.to_datetime(val_df.storeDate, unit='s')\n",
    "val_df.set_index(['storeDate', 'symbol'], inplace=True)\n",
    "val_df.dropna(subset=['premDisc'], inplace=True)\n",
    "tickers = val_df.reset_index().symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_cols = ['forwardPE', 'trailingPE', 'marketCap', 'regularMarketPrice']\n",
    "p_cols = ['sector', 'industry', 'country']\n",
    "k_cols = ['pegRatio', 'shortPercentOfFloat']\n",
    "f_cols = ['earningsGrowth', 'recommendationMean', 'targetMeanPrice', 'targetMedianPrice', 'numberOfAnalystOpinions']\n",
    "for c in p_cols: val_df.loc[:, c] = tickers.map(profile[c].to_dict()).values\n",
    "for c in q_cols: val_df.loc[:, c] = tickers.map(quotes[c].to_dict()).values\n",
    "for c in k_cols: val_df.loc[:, c] = tickers.map(keystats[c].to_dict()).values\n",
    "for c in f_cols: val_df.loc[:, c] = tickers.map(finstats[c].to_dict()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_vals = [\n",
    "    'netDebt', 'npvSteadyCF', 'equityValue', \n",
    "    'currentValue', 'totalReinvCapital', 'steadyCF', 'projCashROE',\n",
    "    'npvGrowth', 'npvGrowthCF', 'projCashROE', 'marketCap']\n",
    "# convert large values to billions\n",
    "val_df.loc[:, large_vals] = val_df.loc[:, large_vals] / 10**9\n",
    "\n",
    "# high level pre-processing / clean up\n",
    "val_df.loc[:, 'pegRatio'] = val_df.forwardPE / (val_df.growthRate * 100)\n",
    "div_cols = ['targetMeanPrice', 'targetMedianPrice']\n",
    "val_df.loc[:, div_cols] = val_df[div_cols].div(\n",
    "    tickers.map(\n",
    "        quotes.regularMarketPrice.to_dict()).values, axis=0)\n",
    "val_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers from universe\n",
    "show = ['premDisc', 'pegRatio', 'forwardPE', 'growthRate', \n",
    "        'shortPercentOfFloat', 'targetMedianPrice']\n",
    "treshold = 3\n",
    "no_out_df = fu.excl_outliers(val_df, show, treshold)\n",
    "no_out_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask results by valuation\n",
    "mask_on = True\n",
    "mask = (val_df.premDisc > 0) & (val_df.premDisc < 3)\n",
    "clean_df = no_out_df.loc[mask].copy() if mask_on else no_out_df.copy()\n",
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one company sampling\n",
    "ticker = 'AAPL'\n",
    "print(ticker in tickers.values, ticker in clean_df.index.levels[1])\n",
    "val_df.loc[(slice(None),ticker),:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate / deep dive metrics\n",
    "gby = ['sector',]\n",
    "gby = ['sector', 'industry', 'symbol'] # by uncommenting this line deep dive into sectors below\n",
    "zoom_in = [x for x in clean_df.sector.unique()] # all sectors\n",
    "zoom_in = ['Healthcare'] # or just a few selected\n",
    "agg_functions = 'median'\n",
    "sort_by = ['premDisc']\n",
    "\n",
    "ind_sum_df = clean_df.groupby(by=gby).agg(agg_functions)[show]\n",
    "if 'symbol' in gby: ind_sum_df = ind_sum_df.loc[(zoom_in,),:]\n",
    "else: ind_sum_df = ind_sum_df\n",
    "ind_sum_df.sort_values(by=sort_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank results relative to sector or entire universe\n",
    "low_better = ['premDisc', 'pegRatio', 'forwardPE', 'shortPercentOfFloat']\n",
    "high_better = ['earningsGrowth', 'targetMedianPrice']\n",
    "cols = low_better + high_better\n",
    "\n",
    "by_sector_on = True\n",
    "\n",
    "rank_df = clean_df.copy()\n",
    "if by_sector_on:\n",
    "    # relative to sector\n",
    "    super_list = []\n",
    "    for s in rank_df.sector.unique():\n",
    "        group = rank_df.loc[rank_df.sector == s, cols]\n",
    "        ranked_df = fu.rank_group(group, low_better, high_better)\n",
    "        super_list.append(ranked_df)\n",
    "    ranked_df = pd.concat(super_list, axis=0)\n",
    "else:\n",
    "    # relative to market\n",
    "    ranked_df = fu.rank_group(rank_df, low_better, high_better)\n",
    "\n",
    "ranked_df.loc[:, 'eq_wgt_mean_rank'] = ranked_df.mean(axis=1)\n",
    "ranked_df.sort_values('eq_wgt_mean_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
