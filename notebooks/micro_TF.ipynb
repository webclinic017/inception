{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading utils/config.json\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.basic_utils import *\n",
    "from utils.fundamental import chain_outlier, get_focus_tickers, train_on_winners\n",
    "from utils.pricing import load_px_close, get_return_intervals \n",
    "from utils.pricing import dummy_col, discret_rets, sample_wgts\n",
    "from utils.pricing import px_mom_feats, px_mom_co_feats_light \n",
    "from utils.pricing import eq_wgt_indices, to_index_form, rename_col\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, log_loss, precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam, Adagrad, Adadelta, Adamax, Nadam, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "bench = '^GSPC'\n",
    "y_col = 'fwdReturn'\n",
    "tickers = excl(config['companies'], [])\n",
    "\n",
    "context = {\n",
    "    'ml_path': '../ML/',\n",
    "    'model_name': 'micro_TF.h5',\n",
    "    'tmp_path': '../tmp/',\n",
    "    'ds_name': 'co-technicals-ds',\n",
    "    'px_close': 'universe-px-ds',\n",
    "    'trained_cols': 'micro_TF_train_cols.npy',\n",
    "    'look_ahead': 120,\n",
    "    'look_back': 252,\n",
    "    'smooth_window': 10,\n",
    "    'load_ds': True,\n",
    "    'scale': True,\n",
    "    'test_size': .02,\n",
    "    'verbose': True,\n",
    "    's3_path': 'recommend/micro_ML/',\n",
    "    'units': 850,\n",
    "    'max_iter': 400,\n",
    "    'l2_reg': 0.009,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get latest pricing file from inferece server\n",
    "px_close_ds = context['px_close']\n",
    "tmp_path = context['tmp_path']\n",
    "os.makedirs(tmp_path, exist_ok=True)\n",
    "!scp -i ~/.ssh/qc_infra.pem ubuntu@54.188.213.105:~/inception/tmp/{px_close_ds} {tmp_path}{px_close_ds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4674 entries, 2004-05-09 to 2019-05-10\n",
      "Columns: 1285 entries, 0700.HK to KRW=X\n",
      "dtypes: float32(1285)\n",
      "memory usage: 22.9+ MB\n",
      "px_close.info() None\n",
      "Return intervals (-inf, -0.17596158385276794, -0.10722249746322632, 0.13989457488059998, 0.2517735958099365, inf)\n"
     ]
    }
   ],
   "source": [
    "# load stored pricing\n",
    "px_close = load_px_close(\n",
    "    context['tmp_path'], context['px_close'], context['load_ds']).drop_duplicates()\n",
    "print('px_close.info()', px_close.info())\n",
    "\n",
    "prices = px_close.dropna(subset=[bench])[tickers]\n",
    "look_ahead = context['look_ahead']\n",
    "cut_range = get_return_intervals(prices, look_ahead, tresholds=[0.25, 0.75])\n",
    "fwd_ret_labels = [\"bear\", \"short\", \"neutral\", \"long\", \"bull\"]\n",
    "print(f'Return intervals {cut_range}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target date: 2019-05-10\n",
      "Loading file quote/csv/2019-05-10\n",
      "Loading file summary-categories/assetProfile\n"
     ]
    }
   ],
   "source": [
    "# latest quotes, profile, and industries\n",
    "dates = read_dates('quote')\n",
    "tgt_date = dates[-1] # last date saved in S3\n",
    "print(f'Target date: {tgt_date}')\n",
    "\n",
    "quotes = load_csvs('quote_consol', [tgt_date])\n",
    "quotes.set_index('symbol', drop=False, inplace=True)\n",
    "\n",
    "profile = load_csvs('summary_detail', ['assetProfile'])\n",
    "profile.set_index('symbol', drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208 companies\n"
     ]
    }
   ],
   "source": [
    "# Smaller subset for testing\n",
    "tgt_sectors = [\n",
    "    'Technology',\n",
    "    'Healthcare',\n",
    "    'Industrials',\n",
    "    'Basic Materials',\n",
    "    'Consumer Cyclical',\n",
    "    'Financial Services',\n",
    "    'Consumer Defensive',\n",
    "    'Real Estate',\n",
    "    'Utilities',\n",
    "    'Communication Services',\n",
    "    'Energy',\n",
    "]\n",
    "\n",
    "# size_df = get_focus_tickers(quotes, profile, tgt_sectors)\n",
    "# tickers = list(size_df.index)\n",
    "# ind_count = size_df.groupby('industry').count()['marketCap']\n",
    "# tgt_industries = list(ind_count.loc[ind_count > ind_count.median() - 1].index)\n",
    "# tickers = list(profile.loc[profile.industry.isin(tgt_industries), 'symbol'])\n",
    "tickers = list(quotes.loc[quotes.quoteType == 'EQUITY', 'symbol'])\n",
    "context['tickers'] = tickers\n",
    "print(f'{len(tickers)} companies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def pre_process_ds(context):\n",
    "    \n",
    "    tickers = context['tickers']\n",
    "    sectors = profile.loc[profile.symbol.isin(tickers)].sector.unique()\n",
    "    industries = profile.loc[profile.symbol.isin(tickers)].industry.unique()\n",
    "    print(f'Sectors: {sectors.shape[0]}, Industries: {industries.shape[0]}')\n",
    "    \n",
    "    indices_df = pd.concat(\n",
    "        [eq_wgt_indices(profile, px_close, 'sector', sectors, subset=tickers),\n",
    "        eq_wgt_indices(profile, px_close, 'industry', industries, subset=tickers),\n",
    "        to_index_form(px_close[bench], bench)], \n",
    "        axis=1).drop_duplicates()\n",
    "    \n",
    "    # create price momentum features\n",
    "    tmp_path = context['tmp_path']\n",
    "    ds_name = context['ds_name']\n",
    "\n",
    "    super_list = []\n",
    "    for i, ticker in tqdm(enumerate(tickers)):\n",
    "        try:\n",
    "            close = px_close[ticker].dropna()\n",
    "            ft_df = px_mom_feats(close, ticker, incl_name=False)\n",
    "            if ticker in profile.symbol.unique():\n",
    "                top_groups = tuple([bench, profile.loc[ticker, 'sector']])\n",
    "                co = px_mom_co_feats_light(close, indices_df, top_groups)\n",
    "                ft_df = pd.concat([ft_df, co.loc[ft_df.index, :]], axis=1)\n",
    "                super_list.append(ft_df.copy())\n",
    "            else: print(ticker, 'missing profile, skipping')\n",
    "        except Exception as e: \n",
    "            print(\"Exception: {0} {1}\".format(ticker, e))\n",
    "\n",
    "    joined_df = pd.concat(super_list, axis=0)\n",
    "    joined_df = chain_outlier(joined_df, None)\n",
    "        \n",
    "    # basic impute and scaling\n",
    "    scale_on = context['scale']\n",
    "    scaler = StandardScaler()\n",
    "    num_cols = numeric_cols(joined_df)\n",
    "    joined_df.loc[:, num_cols] = joined_df[num_cols].replace([np.inf, -np.inf, np.nan], 0)\n",
    "    if scale_on: joined_df.loc[:, num_cols] = scaler.fit_transform(joined_df[num_cols])\n",
    "\n",
    "    # add categoricals\n",
    "    joined_df = dummy_col(joined_df, 'sector', shorten=True)\n",
    "    \n",
    "    return joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_train_test_sets(context):\n",
    "    \n",
    "    verbose = context['verbose']\n",
    "    ml_path, model_name = context['ml_path'], context['model_name']\n",
    "    trained_cols = context['trained_cols']    \n",
    "    test_size = context['test_size']    \n",
    "    look_ahead, look_back, smooth_window = context['look_ahead'], context['look_back'], context['smooth_window']\n",
    "\n",
    "    narrow_list = list(train_on_winners(prices, context['tickers'], 10, 0.75).index)\n",
    "    context['tickers'] = narrow_list\n",
    "    print(f'Training on {len(context[\"tickers\"])} companies')\n",
    "\n",
    "    joined_df = pre_process_ds(context)\n",
    "\n",
    "    # if we want to limit training set\n",
    "    # index = joined_df.sort_index().index.unique()[-look_back:]\n",
    "    # joined_df = joined_df.loc[index, :]\n",
    "    # joined_df.shape\n",
    "\n",
    "    # calculation of forward returns\n",
    "    Y = px_close.loc[:, tickers].pct_change(look_ahead).shift(-look_ahead)\n",
    "    Y = Y.rolling(smooth_window).mean() # smooth by the same length\n",
    "    Y = Y[~(Y.isna().all(1))]\n",
    "    Y = Y.loc[joined_df.index.unique(), :]\n",
    "\n",
    "    # reshapes to include symbol in index in additional to date\n",
    "    Y_df = Y.loc[joined_df.index.unique().sortlevel()[0], tickers]\n",
    "    Y_df = Y_df.stack().to_frame().rename(columns={0: y_col})\n",
    "    # somwhat repetitive with steps above but performs faster\n",
    "    Y_df.index.set_names(['storeDate', 'symbol'], inplace=True)\n",
    "    print('Y_df.shape', Y_df.shape)\n",
    "\n",
    "    # re-index processed df on storeDate and symbol to have similar indices\n",
    "    joined_df.index.set_names('storeDate', inplace=True)\n",
    "    joined_df.set_index(['symbol'], append=True, inplace=True)\n",
    "    print('joined_df.shape', joined_df.shape)\n",
    "\n",
    "    # add Y values to processed df fast without having to loop\n",
    "    joined_df.loc[:, y_col] = Y_df.loc[joined_df.index, y_col]\n",
    "\n",
    "    # joined_df.loc[(slice(None), 'AAPL'), y_col].plot() # visualize smoothing\n",
    "    # joined_df.groupby('symbol')[y_col].mean().sort_values() # rank long-term mean performance\n",
    "\n",
    "    # discretize Y-variable\n",
    "    joined_df.dropna(subset=[y_col], inplace=True)\n",
    "    joined_df[y_col] = discret_rets(joined_df[y_col], cut_range, fwd_ret_labels)\n",
    "    print('joined_df.shape', joined_df.shape)\n",
    "    print(sample_wgts(joined_df[y_col]))\n",
    "\n",
    "    joined_df.dropna(subset=[y_col], inplace=True)\n",
    "    joined_df.loc[:, y_col] = joined_df[y_col].astype(str)\n",
    "\n",
    "    days = len(joined_df.index.levels[0].unique())\n",
    "    print(f'Training for {days} dates, {round(days/252, 1)} years')\n",
    "\n",
    "    # joined_df.loc[(slice(None), 'TAL'), y_col].value_counts() # look at a specific security distribution\n",
    "    train_df = joined_df.reset_index(drop=True)\n",
    "    train_df.shape\n",
    "\n",
    "    # create training and test sets\n",
    "    X, y = train_df.drop(columns=y_col), train_df[y_col]\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        break # just one split\n",
    "\n",
    "    # skf = StratifiedKFold(n_splits=2, random_state=None)\n",
    "    # for train_index, test_index in skf.split(X, y):\n",
    "    #     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    #     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    #     break\n",
    "          \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train_ds(context):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = get_train_test_sets(context)\n",
    "    \n",
    "    # Keras Model\n",
    "    max_iter = context['max_iter']\n",
    "    l2_reg = context['l2_reg']\n",
    "    units = context['units']\n",
    "    trained_cols = context['trained_cols']\n",
    "\n",
    "    y_train_oh = pd.get_dummies(y_train)[fwd_ret_labels]\n",
    "    y_test_oh = pd.get_dummies(y_test)[fwd_ret_labels]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_dim=X_train.shape[1]))\n",
    "    # model.add(Dropout(0.05))\n",
    "    model.add(Dense(units, activation='relu'))\n",
    "    model.add(Dense(units, activation='relu'))\n",
    "    model.add(Dense(units, activation='relu'))\n",
    "    model.add(Dense(int(units/2), activation='relu'))\n",
    "    model.add(Dense(len(pd.unique(y_train)), activation='softmax'))\n",
    "    keras.regularizers.l2(l2_reg)\n",
    "\n",
    "    opt = Adam()\n",
    "    # opt = Nadam() #essentially RMSprop with momentum, Nadam is Adam RMSprop with Nesterov momentum\n",
    "    # opt = RMSprop() #optimizer is usually a good choice for recurrent neural networks\n",
    "\n",
    "    ml_path, model_name = context['ml_path'], context['model_name']\n",
    "    fname = ml_path + model_name\n",
    "    es = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "    checkpointer = ModelCheckpoint(filepath=fname, verbose=1, save_best_only=True)\n",
    "    csv_logger = CSVLogger('micro-train.log')\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train_oh, validation_data=(X_test, y_test_oh), \n",
    "              epochs=max_iter, batch_size=200, callbacks=[es, checkpointer, csv_logger])\n",
    "\n",
    "    score = model.evaluate(X_test, y_test_oh)\n",
    "    print(f'Test loss: {score[0]}, Test accuracy: {score[1]}')\n",
    "\n",
    "    # save training columns\n",
    "    np.save(ml_path + trained_cols, X_train.columns) # save feature order\n",
    "    print(f'X_train.shape {X_train.shape}, columns: {list(X_train.columns)}')\n",
    "    print('Saved: ', ml_path + trained_cols)\n",
    "\n",
    "    # save model to drive\n",
    "    model.save(fname)\n",
    "    print('Saved ', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def predict_ds(context):\n",
    "    \n",
    "    ml_path = context['ml_path']\n",
    "    model_name = context['model_name']\n",
    "    trained_cols = context['trained_cols']\n",
    "\n",
    "    joined_df = create_pre_process_ds(context)\n",
    "    pred_X = joined_df.loc[joined_df.sort_index().index[-1], :]\n",
    "    print('pred_X.shape', pred_X.shape)\n",
    "\n",
    "    # ensure prediction dataset is consistent with trained model\n",
    "    train_cols = np.load(ml_path + trained_cols) # save feature order\n",
    "    missing_cols = [x for x in train_cols if x not in pred_X.columns]\n",
    "    if len(missing_cols):\n",
    "        print(f'Warning missing columns: {missing_cols}')\n",
    "        pred_X = pd.concat([pred_X, pd.DataFrame(columns=missing_cols)], axis=1)\n",
    "        pred_X[missing_cols] = 0\n",
    "\n",
    "    sorted_cols = list(np.append(train_cols, ['symbol']))\n",
    "    print('pred_X.shape', pred_X[sorted_cols].shape)\n",
    "\n",
    "    pred_df = pd.DataFrame()\n",
    "    pred_df['symbol'] = pred_X.symbol\n",
    "\n",
    "    # Load model    \n",
    "    fname = ml_path + model_name\n",
    "    model = load_model(fname)\n",
    "    print('Loaded', fname)\n",
    "\n",
    "    preds = model.predict(pred_X[sorted_cols].iloc[:, :-1])\n",
    "    preds_classes = model.predict_classes(pred_X[sorted_cols].iloc[:, :-1])    \n",
    "    \n",
    "    pred_df['pred_class'] = preds_classes\n",
    "    pred_df['pred_label'] = list(map(lambda x: fwd_ret_labels[x], preds_classes))\n",
    "    probs = np.round(preds,3)\n",
    "    pred_prob = np.argmax(probs, axis=1)\n",
    "    pred_df['confidence'] = [x[np.argmax(x)] for x in probs] # higest prob\n",
    "    prob_df = pd.DataFrame(probs, index=pred_df.index, columns=fwd_ret_labels)\n",
    "    pred_df = pd.concat([pred_df, prob_df[fwd_ret_labels]], axis=1)\n",
    "    pred_df.index.name = 'pred_date'\n",
    "\n",
    "    # store in S3\n",
    "    s3_path = context['s3_path']\n",
    "    s3_df = pred_df.reset_index(drop=False)\n",
    "    rename_col(s3_df, 'index', 'pred_date')\n",
    "    csv_store(s3_df, s3_path, csv_ext.format(tgt_date))\n",
    "            \n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_sets(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/miniconda3/envs/inception/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/miniconda3/envs/inception/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 843636 samples, validate on 17218 samples\n",
      "Epoch 1/400\n",
      "843636/843636 [==============================] - 86s 102us/step - loss: 1.2325 - acc: 0.5208 - val_loss: 1.1542 - val_acc: 0.5455\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.15418, saving model to ../ML/micro_TF.h5\n",
      "Epoch 2/400\n",
      "843636/843636 [==============================] - 85s 101us/step - loss: 1.0900 - acc: 0.5676 - val_loss: 1.0177 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.15418 to 1.01766, saving model to ../ML/micro_TF.h5\n",
      "Epoch 3/400\n",
      "843636/843636 [==============================] - 85s 101us/step - loss: 0.9274 - acc: 0.6299 - val_loss: 0.8688 - val_acc: 0.6554\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.01766 to 0.86881, saving model to ../ML/micro_TF.h5\n",
      "Epoch 4/400\n",
      "843636/843636 [==============================] - 84s 100us/step - loss: 0.7822 - acc: 0.6890 - val_loss: 0.7600 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.86881 to 0.76004, saving model to ../ML/micro_TF.h5\n",
      "Epoch 5/400\n",
      "843636/843636 [==============================] - 85s 100us/step - loss: 0.6695 - acc: 0.7361 - val_loss: 0.6728 - val_acc: 0.7377\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.76004 to 0.67280, saving model to ../ML/micro_TF.h5\n",
      "Epoch 6/400\n",
      "843636/843636 [==============================] - 85s 100us/step - loss: 0.5856 - acc: 0.7703 - val_loss: 0.6125 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.67280 to 0.61255, saving model to ../ML/micro_TF.h5\n",
      "Epoch 7/400\n",
      "843636/843636 [==============================] - 85s 100us/step - loss: 0.5212 - acc: 0.7965 - val_loss: 0.5893 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.61255 to 0.58927, saving model to ../ML/micro_TF.h5\n",
      "Epoch 8/400\n",
      "843636/843636 [==============================] - 60s 71us/step - loss: 0.4711 - acc: 0.8169 - val_loss: 0.5502 - val_acc: 0.7905\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.58927 to 0.55017, saving model to ../ML/micro_TF.h5\n",
      "Epoch 9/400\n",
      "843636/843636 [==============================] - 43s 50us/step - loss: 0.4316 - acc: 0.8330 - val_loss: 0.5111 - val_acc: 0.8097\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.55017 to 0.51106, saving model to ../ML/micro_TF.h5\n",
      "Epoch 10/400\n",
      "843636/843636 [==============================] - 43s 51us/step - loss: 0.3991 - acc: 0.8462 - val_loss: 0.5012 - val_acc: 0.8118\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.51106 to 0.50125, saving model to ../ML/micro_TF.h5\n",
      "Epoch 11/400\n",
      "843636/843636 [==============================] - 42s 49us/step - loss: 0.3707 - acc: 0.8573 - val_loss: 0.4849 - val_acc: 0.8222\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.50125 to 0.48494, saving model to ../ML/micro_TF.h5\n",
      "Epoch 12/400\n",
      "843636/843636 [==============================] - 42s 49us/step - loss: 0.3481 - acc: 0.8665 - val_loss: 0.4687 - val_acc: 0.8297\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.48494 to 0.46872, saving model to ../ML/micro_TF.h5\n",
      "Epoch 13/400\n",
      "843636/843636 [==============================] - 42s 50us/step - loss: 0.3279 - acc: 0.8743 - val_loss: 0.4589 - val_acc: 0.8339\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.46872 to 0.45889, saving model to ../ML/micro_TF.h5\n",
      "Epoch 14/400\n",
      "843636/843636 [==============================] - 42s 49us/step - loss: 0.3116 - acc: 0.8810 - val_loss: 0.4444 - val_acc: 0.8411\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.45889 to 0.44443, saving model to ../ML/micro_TF.h5\n",
      "Epoch 15/400\n",
      "843636/843636 [==============================] - 41s 49us/step - loss: 0.2971 - acc: 0.8869 - val_loss: 0.4375 - val_acc: 0.8466\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.44443 to 0.43749, saving model to ../ML/micro_TF.h5\n",
      "Epoch 16/400\n",
      "843636/843636 [==============================] - 41s 49us/step - loss: 0.2840 - acc: 0.8921 - val_loss: 0.4500 - val_acc: 0.8440\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.43749\n",
      "Epoch 17/400\n",
      "843636/843636 [==============================] - 70s 83us/step - loss: 0.2716 - acc: 0.8968 - val_loss: 0.4390 - val_acc: 0.8493\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.43749\n",
      "Epoch 18/400\n",
      "843636/843636 [==============================] - 71s 84us/step - loss: 0.2622 - acc: 0.9006 - val_loss: 0.4370 - val_acc: 0.8522\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.43749 to 0.43699, saving model to ../ML/micro_TF.h5\n",
      "Epoch 19/400\n",
      "843636/843636 [==============================] - 71s 84us/step - loss: 0.2527 - acc: 0.9044 - val_loss: 0.4275 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.43699 to 0.42752, saving model to ../ML/micro_TF.h5\n",
      "Epoch 20/400\n",
      "843636/843636 [==============================] - 71s 84us/step - loss: 0.2439 - acc: 0.9079 - val_loss: 0.4257 - val_acc: 0.8563\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.42752 to 0.42570, saving model to ../ML/micro_TF.h5\n",
      "Epoch 21/400\n",
      "843636/843636 [==============================] - 71s 84us/step - loss: 0.2363 - acc: 0.9109 - val_loss: 0.4208 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.42570 to 0.42083, saving model to ../ML/micro_TF.h5\n",
      "Epoch 22/400\n",
      "843636/843636 [==============================] - 71s 84us/step - loss: 0.2300 - acc: 0.9139 - val_loss: 0.4329 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.42083\n",
      "Epoch 23/400\n",
      "843636/843636 [==============================] - 71s 85us/step - loss: 0.2245 - acc: 0.9158 - val_loss: 0.4157 - val_acc: 0.8617\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.42083 to 0.41568, saving model to ../ML/micro_TF.h5\n",
      "Epoch 24/400\n",
      "843636/843636 [==============================] - 71s 84us/step - loss: 0.2188 - acc: 0.9181 - val_loss: 0.4280 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.41568\n",
      "Epoch 25/400\n",
      "376200/843636 [============>.................] - ETA: 39s - loss: 0.2051 - acc: 0.9234"
     ]
    }
   ],
   "source": [
    "# Keras Model\n",
    "max_iter = context['max_iter']\n",
    "l2_reg = context['l2_reg']\n",
    "units = context['units']\n",
    "trained_cols = context['trained_cols']\n",
    "\n",
    "y_train_oh = pd.get_dummies(y_train)[fwd_ret_labels]\n",
    "y_test_oh = pd.get_dummies(y_test)[fwd_ret_labels]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units, activation='relu', input_dim=X_train.shape[1]))\n",
    "# model.add(Dropout(0.05))\n",
    "model.add(Dense(units, activation='relu'))\n",
    "model.add(Dense(units, activation='relu'))\n",
    "model.add(Dense(units, activation='relu'))\n",
    "model.add(Dense(int(units/2), activation='relu'))\n",
    "model.add(Dense(len(pd.unique(y_train)), activation='softmax'))\n",
    "keras.regularizers.l2(l2_reg)\n",
    "\n",
    "opt = Adam()\n",
    "# opt = Nadam() #essentially RMSprop with momentum, Nadam is Adam RMSprop with Nesterov momentum\n",
    "# opt = RMSprop() #optimizer is usually a good choice for recurrent neural networks\n",
    "\n",
    "ml_path, model_name = context['ml_path'], context['model_name']\n",
    "fname = ml_path + model_name\n",
    "es = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=fname, verbose=1, save_best_only=True)\n",
    "csv_logger = CSVLogger('micro-train.log')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train_oh, validation_data=(X_test, y_test_oh), \n",
    "          epochs=max_iter, batch_size=200, callbacks=[es, checkpointer, csv_logger])\n",
    "\n",
    "score = model.evaluate(X_test, y_test_oh)\n",
    "print(f'Test loss: {score[0]}, Test accuracy: {score[1]}')\n",
    "\n",
    "# save training columns\n",
    "np.save(ml_path + trained_cols, X_train.columns) # save feature order\n",
    "print(f'X_train.shape {X_train.shape}, columns: {list(X_train.columns)}')\n",
    "print('Saved: ', ml_path + trained_cols)\n",
    "\n",
    "# save model to drive\n",
    "model.save(fname)\n",
    "print('Saved ', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model    \n",
    "fname = ml_path + model_name\n",
    "model = load_model(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17490/17490 [==============================] - 4s 243us/step\n",
      "Test loss: 0.5249564689745421, Test accuracy: 0.89399656944782\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test_oh)\n",
    "print(f'Test loss: {score[0]}, Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 245 companies\n",
      "Sectors: 11, Industries: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/pandas/core/indexing.py:1017: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return getattr(section, self.name)[new_key]\n",
      "245it [00:23, 10.57it/s]\n",
      "/home/ec2-user/SageMaker/inception/notebooks/utils/fundamental.py:58: RuntimeWarning: invalid value encountered in maximum\n",
      "  df[nums] = np.minimum(np.maximum(df[nums], p1[nums]), p99[nums])\n",
      "/home/ec2-user/SageMaker/inception/notebooks/utils/fundamental.py:58: RuntimeWarning: invalid value encountered in minimum\n",
      "  df[nums] = np.minimum(np.maximum(df[nums], p1[nums]), p99[nums])\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/pandas/core/indexing.py:1494: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_df.shape (3900803, 1)\n",
      "joined_df.shape (899674, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/pandas/core/indexing.py:969: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_nested_tuple(tup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined_df.shape (874489, 29)\n",
      "neutral   0.48\n",
      "long      0.18\n",
      "bull      0.17\n",
      "bear      0.11\n",
      "short     0.06\n",
      "Name: fwdReturn, dtype: float64\n",
      "Training for 3864 dates, 15.3 years\n",
      "max_iter: 400, l2_reg: 0.005, neuron_mult: 30, units: 750\n",
      "Train on 856999 samples, validate on 17490 samples\n",
      "Epoch 1/400\n",
      "571400/856999 [===================>..........] - ETA: 37s - loss: 1.2591 - acc: 0.5105"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-101-f682af72f739>\u001b[0m in \u001b[0;36mtrain_ds\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     history = model.fit(X_train, y_train_oh, validation_data=(X_test, y_test_oh), \n\u001b[0;32m--> 104\u001b[0;31m               epochs=max_iter, batch_size=200, callbacks=[es, checkpointer,])\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_oh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time train_ds(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lht {ml_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sectors: 1, Industries: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/pandas/core/indexing.py:1017: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return getattr(section, self.name)[new_key]\n",
      "\n",
      "2it [00:00, 12.09it/s]\u001b[A\n",
      "4it [00:00, 11.82it/s]\u001b[A\n",
      "6it [00:00, 11.68it/s]\u001b[A\n",
      "8it [00:00, 12.04it/s]\u001b[A\n",
      "10it [00:00, 11.76it/s]\u001b[A\n",
      "12it [00:01, 11.57it/s]\u001b[A\n",
      "14it [00:01, 11.93it/s]\u001b[A\n",
      "16it [00:01, 11.68it/s]\u001b[A\n",
      "18it [00:01, 12.01it/s]\u001b[A\n",
      "20it [00:01, 12.21it/s]\u001b[A/home/ec2-user/SageMaker/inception/notebooks/utils/fundamental.py:58: RuntimeWarning: invalid value encountered in maximum\n",
      "  df[nums] = np.minimum(np.maximum(df[nums], p1[nums]), p99[nums])\n",
      "/home/ec2-user/SageMaker/inception/notebooks/utils/fundamental.py:58: RuntimeWarning: invalid value encountered in minimum\n",
      "  df[nums] = np.minimum(np.maximum(df[nums], p1[nums]), p99[nums])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_X.shape (20, 19)\n",
      "pred_X.shape (20, 19)\n",
      "Loaded ../ML/micro_TF.pkl\n",
      "Saved recommend/micro_ML/2019-05-08.csv\n",
      "CPU times: user 17.2 s, sys: 0 ns, total: 17.2 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "# predict for all\n",
    "%time pred_df = predict_ds(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store / Read S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = context['s3_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from S3\n",
    "pred_df = pd.read_csv(\n",
    "    csv_load(f'{s3_path}{tgt_date}'), \n",
    "    index_col='pred_date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>bear</th>\n",
       "      <th>short</th>\n",
       "      <th>neutral</th>\n",
       "      <th>long</th>\n",
       "      <th>bull</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>AMT</td>\n",
       "      <td>3</td>\n",
       "      <td>long</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>AMX</td>\n",
       "      <td>4</td>\n",
       "      <td>bull</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>BT</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>CABO</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>CCOI</td>\n",
       "      <td>1</td>\n",
       "      <td>short</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>CHL</td>\n",
       "      <td>4</td>\n",
       "      <td>bull</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>CHTR</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>CHU</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>CMCSA</td>\n",
       "      <td>3</td>\n",
       "      <td>long</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>CTL</td>\n",
       "      <td>3</td>\n",
       "      <td>long</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>DISH</td>\n",
       "      <td>4</td>\n",
       "      <td>bull</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>IDCC</td>\n",
       "      <td>3</td>\n",
       "      <td>long</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>IRDM</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>KDDIY</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>KT</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>ORAN</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>SBAC</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>SFTBY</td>\n",
       "      <td>3</td>\n",
       "      <td>long</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>SKM</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>short</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>TDS</td>\n",
       "      <td>1</td>\n",
       "      <td>short</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>TEF</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>TKC</td>\n",
       "      <td>4</td>\n",
       "      <td>bull</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>TSU</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>VEON</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>VG</td>\n",
       "      <td>0</td>\n",
       "      <td>bear</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>VIV</td>\n",
       "      <td>4</td>\n",
       "      <td>bull</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>VOD</td>\n",
       "      <td>0</td>\n",
       "      <td>bear</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>VZ</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           symbol  pred_class pred_label  confidence  bear  short  neutral  \\\n",
       "pred_date                                                                    \n",
       "2019-05-01    AMT           3       long        1.00  0.00   0.00     0.00   \n",
       "2019-05-01    AMX           4       bull        0.98  0.00   0.00     0.00   \n",
       "2019-05-01     BT           2    neutral        1.00  0.00   0.00     1.00   \n",
       "2019-05-01   CABO           2    neutral        1.00  0.00   0.00     1.00   \n",
       "2019-05-01   CCOI           1      short        0.63  0.00   0.63     0.37   \n",
       "2019-05-01    CHL           4       bull        0.98  0.00   0.00     0.01   \n",
       "2019-05-01   CHTR           2    neutral        0.99  0.00   0.01     0.99   \n",
       "2019-05-01    CHU           2    neutral        1.00  0.00   0.00     1.00   \n",
       "2019-05-01  CMCSA           3       long        0.99  0.00   0.00     0.01   \n",
       "2019-05-01    CTL           3       long        0.99  0.01   0.00     0.00   \n",
       "2019-05-01   DISH           4       bull        0.93  0.00   0.00     0.06   \n",
       "2019-05-01   IDCC           3       long        1.00  0.00   0.00     0.00   \n",
       "2019-05-01   IRDM           2    neutral        0.91  0.00   0.00     0.91   \n",
       "2019-05-01  KDDIY           2    neutral        1.00  0.00   0.00     1.00   \n",
       "2019-05-01     KT           2    neutral        0.98  0.00   0.00     0.98   \n",
       "2019-05-01   ORAN           2    neutral        1.00  0.00   0.00     1.00   \n",
       "2019-05-01   SBAC           2    neutral        1.00  0.00   0.00     1.00   \n",
       "2019-05-01  SFTBY           3       long        0.85  0.00   0.00     0.15   \n",
       "2019-05-01    SKM           2    neutral        1.00  0.00   0.00     1.00   \n",
       "2019-05-01      T           1      short        0.98  0.00   0.98     0.02   \n",
       "2019-05-01    TDS           1      short        0.99  0.00   0.99     0.01   \n",
       "2019-05-01    TEF           2    neutral        1.00  0.00   0.00     1.00   \n",
       "2019-05-01    TKC           4       bull        0.94  0.00   0.06     0.00   \n",
       "2019-05-01    TSU           2    neutral        1.00  0.00   0.00     1.00   \n",
       "2019-05-01   VEON           2    neutral        0.52  0.00   0.00     0.52   \n",
       "2019-05-01     VG           0       bear        0.80  0.80   0.00     0.19   \n",
       "2019-05-01    VIV           4       bull        0.99  0.00   0.00     0.00   \n",
       "2019-05-01    VOD           0       bear        0.80  0.80   0.00     0.20   \n",
       "2019-05-01     VZ           2    neutral        1.00  0.00   0.00     1.00   \n",
       "\n",
       "            long  bull  \n",
       "pred_date               \n",
       "2019-05-01  1.00  0.00  \n",
       "2019-05-01  0.02  0.98  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.00  0.98  \n",
       "2019-05-01  0.01  0.00  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.99  0.00  \n",
       "2019-05-01  0.99  0.00  \n",
       "2019-05-01  0.01  0.93  \n",
       "2019-05-01  1.00  0.00  \n",
       "2019-05-01  0.00  0.09  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.02  0.00  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.85  0.00  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.00  0.94  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.48  0.00  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.01  0.99  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.00  0.00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral    14\n",
       "long        5\n",
       "bull        5\n",
       "short       3\n",
       "bear        2\n",
       "Name: pred_label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommendation distribution\n",
    "pd.value_counts(pred_df.pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>bear</th>\n",
       "      <th>short</th>\n",
       "      <th>neutral</th>\n",
       "      <th>long</th>\n",
       "      <th>bull</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>VG</td>\n",
       "      <td>0</td>\n",
       "      <td>bear</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>VOD</td>\n",
       "      <td>0</td>\n",
       "      <td>bear</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>VIV</td>\n",
       "      <td>4</td>\n",
       "      <td>bull</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>CHL</td>\n",
       "      <td>4</td>\n",
       "      <td>bull</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>AMX</td>\n",
       "      <td>4</td>\n",
       "      <td>bull</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>TKC</td>\n",
       "      <td>4</td>\n",
       "      <td>bull</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>DISH</td>\n",
       "      <td>4</td>\n",
       "      <td>bull</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>IDCC</td>\n",
       "      <td>3</td>\n",
       "      <td>long</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>AMT</td>\n",
       "      <td>3</td>\n",
       "      <td>long</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>CTL</td>\n",
       "      <td>3</td>\n",
       "      <td>long</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>CMCSA</td>\n",
       "      <td>3</td>\n",
       "      <td>long</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>SFTBY</td>\n",
       "      <td>3</td>\n",
       "      <td>long</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>TDS</td>\n",
       "      <td>1</td>\n",
       "      <td>short</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>short</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>CCOI</td>\n",
       "      <td>1</td>\n",
       "      <td>short</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           symbol  pred_class pred_label  confidence  bear  short  neutral  \\\n",
       "pred_date                                                                    \n",
       "2019-05-01     VG           0       bear        0.80  0.80   0.00     0.19   \n",
       "2019-05-01    VOD           0       bear        0.80  0.80   0.00     0.20   \n",
       "2019-05-01    VIV           4       bull        0.99  0.00   0.00     0.00   \n",
       "2019-05-01    CHL           4       bull        0.98  0.00   0.00     0.01   \n",
       "2019-05-01    AMX           4       bull        0.98  0.00   0.00     0.00   \n",
       "2019-05-01    TKC           4       bull        0.94  0.00   0.06     0.00   \n",
       "2019-05-01   DISH           4       bull        0.93  0.00   0.00     0.06   \n",
       "2019-05-01   IDCC           3       long        1.00  0.00   0.00     0.00   \n",
       "2019-05-01    AMT           3       long        1.00  0.00   0.00     0.00   \n",
       "2019-05-01    CTL           3       long        0.99  0.01   0.00     0.00   \n",
       "2019-05-01  CMCSA           3       long        0.99  0.00   0.00     0.01   \n",
       "2019-05-01  SFTBY           3       long        0.85  0.00   0.00     0.15   \n",
       "2019-05-01    TDS           1      short        0.99  0.00   0.99     0.01   \n",
       "2019-05-01      T           1      short        0.98  0.00   0.98     0.02   \n",
       "2019-05-01   CCOI           1      short        0.63  0.00   0.63     0.37   \n",
       "\n",
       "            long  bull  \n",
       "pred_date               \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.01  0.99  \n",
       "2019-05-01  0.00  0.98  \n",
       "2019-05-01  0.02  0.98  \n",
       "2019-05-01  0.00  0.94  \n",
       "2019-05-01  0.01  0.93  \n",
       "2019-05-01  1.00  0.00  \n",
       "2019-05-01  1.00  0.00  \n",
       "2019-05-01  0.99  0.00  \n",
       "2019-05-01  0.99  0.00  \n",
       "2019-05-01  0.85  0.00  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.00  0.00  \n",
       "2019-05-01  0.00  0.00  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 3 picks by label\n",
    "label_mask = pred_df.pred_label.isin(['bear', 'short', 'long', 'bull'])\n",
    "pred_df.loc[label_mask]\\\n",
    "    .sort_values(by='confidence', ascending=False)\\\n",
    "    .groupby(by='pred_label').head(20)\\\n",
    "    .sort_values(by='pred_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Other experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Narrow training universe to outperformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "narrow_list = list(train_on_winners(prices, tickers, 10, 0.75).index)\n",
    "print(f'{len(narrow_list)} companies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "q_df = quotes.loc[narrow_list, ['shortName', 'marketCap']]\n",
    "p_df = profile.loc[narrow_list, ['sector', 'industry', 'country']]\n",
    "joined_df = pd.concat([hist_return[narrow_list], q_df, p_df], axis=1)\n",
    "joined_df.marketCap = joined_df.marketCap / 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>5%</th>\n",
       "      <th>50%</th>\n",
       "      <th>95%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sector</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Energy</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.74</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>2.00</td>\n",
       "      <td>5.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>5.01</td>\n",
       "      <td>5.02</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.09</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real Estate</th>\n",
       "      <td>5.00</td>\n",
       "      <td>6.38</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.55</td>\n",
       "      <td>5.11</td>\n",
       "      <td>10.76</td>\n",
       "      <td>12.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>61.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.82</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.40</td>\n",
       "      <td>6.73</td>\n",
       "      <td>14.78</td>\n",
       "      <td>24.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industrials</th>\n",
       "      <td>43.00</td>\n",
       "      <td>8.06</td>\n",
       "      <td>3.97</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.64</td>\n",
       "      <td>6.62</td>\n",
       "      <td>15.83</td>\n",
       "      <td>21.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Basic Materials</th>\n",
       "      <td>10.00</td>\n",
       "      <td>8.12</td>\n",
       "      <td>5.08</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.71</td>\n",
       "      <td>5.95</td>\n",
       "      <td>17.40</td>\n",
       "      <td>19.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer Defensive</th>\n",
       "      <td>8.00</td>\n",
       "      <td>8.58</td>\n",
       "      <td>3.66</td>\n",
       "      <td>5.44</td>\n",
       "      <td>5.50</td>\n",
       "      <td>7.83</td>\n",
       "      <td>14.58</td>\n",
       "      <td>16.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Financial Services</th>\n",
       "      <td>23.00</td>\n",
       "      <td>8.78</td>\n",
       "      <td>8.27</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.33</td>\n",
       "      <td>5.99</td>\n",
       "      <td>25.30</td>\n",
       "      <td>39.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Healthcare</th>\n",
       "      <td>41.00</td>\n",
       "      <td>9.15</td>\n",
       "      <td>6.34</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.51</td>\n",
       "      <td>7.11</td>\n",
       "      <td>25.19</td>\n",
       "      <td>32.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer Cyclical</th>\n",
       "      <td>46.00</td>\n",
       "      <td>10.43</td>\n",
       "      <td>9.83</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.67</td>\n",
       "      <td>6.67</td>\n",
       "      <td>27.84</td>\n",
       "      <td>55.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Communication Services</th>\n",
       "      <td>4.00</td>\n",
       "      <td>11.46</td>\n",
       "      <td>10.69</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.46</td>\n",
       "      <td>6.49</td>\n",
       "      <td>24.42</td>\n",
       "      <td>27.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count  mean   std  min   5%  50%   95%   max\n",
       "sector                                                              \n",
       "Energy                   2.00  4.58  0.24 4.42 4.43 4.58  4.74  4.75\n",
       "Utilities                2.00  5.05  0.06 5.01 5.02 5.05  5.09  5.09\n",
       "Real Estate              5.00  6.38  3.22 4.47 4.55 5.11 10.76 12.11\n",
       "Technology              61.00  8.00  3.82 4.24 4.40 6.73 14.78 24.93\n",
       "Industrials             43.00  8.06  3.97 4.20 4.64 6.62 15.83 21.18\n",
       "Basic Materials         10.00  8.12  5.08 4.50 4.71 5.95 17.40 19.99\n",
       "Consumer Defensive       8.00  8.58  3.66 5.44 5.50 7.83 14.58 16.51\n",
       "Financial Services      23.00  8.78  8.27 4.30 4.33 5.99 25.30 39.83\n",
       "Healthcare              41.00  9.15  6.34 4.31 4.51 7.11 25.19 32.68\n",
       "Consumer Cyclical       46.00 10.43  9.83 4.27 4.67 6.67 27.84 55.76\n",
       "Communication Services   4.00 11.46 10.69 5.42 5.46 6.49 24.42 27.44"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_winners = joined_df.groupby(by=['sector']).describe(percentiles=[0.05, 0.95])\n",
    "group_winners['totalReturn'].sort_values(by='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>5%</th>\n",
       "      <th>50%</th>\n",
       "      <th>95%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sector</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Basic Materials</th>\n",
       "      <td>10.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>11.98</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.18</td>\n",
       "      <td>3.12</td>\n",
       "      <td>24.70</td>\n",
       "      <td>40.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>2.00</td>\n",
       "      <td>14.68</td>\n",
       "      <td>6.27</td>\n",
       "      <td>10.25</td>\n",
       "      <td>10.69</td>\n",
       "      <td>14.68</td>\n",
       "      <td>18.67</td>\n",
       "      <td>19.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real Estate</th>\n",
       "      <td>5.00</td>\n",
       "      <td>16.46</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.43</td>\n",
       "      <td>5.05</td>\n",
       "      <td>13.79</td>\n",
       "      <td>35.47</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer Defensive</th>\n",
       "      <td>8.00</td>\n",
       "      <td>26.09</td>\n",
       "      <td>19.10</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.63</td>\n",
       "      <td>26.81</td>\n",
       "      <td>53.04</td>\n",
       "      <td>60.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Energy</th>\n",
       "      <td>2.00</td>\n",
       "      <td>26.58</td>\n",
       "      <td>0.95</td>\n",
       "      <td>25.91</td>\n",
       "      <td>25.98</td>\n",
       "      <td>26.58</td>\n",
       "      <td>27.18</td>\n",
       "      <td>27.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Healthcare</th>\n",
       "      <td>41.00</td>\n",
       "      <td>26.84</td>\n",
       "      <td>40.72</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2.38</td>\n",
       "      <td>13.21</td>\n",
       "      <td>94.30</td>\n",
       "      <td>227.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industrials</th>\n",
       "      <td>43.00</td>\n",
       "      <td>27.12</td>\n",
       "      <td>39.13</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2.87</td>\n",
       "      <td>11.62</td>\n",
       "      <td>118.51</td>\n",
       "      <td>202.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Communication Services</th>\n",
       "      <td>4.00</td>\n",
       "      <td>28.42</td>\n",
       "      <td>38.79</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.62</td>\n",
       "      <td>13.18</td>\n",
       "      <td>75.53</td>\n",
       "      <td>84.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Financial Services</th>\n",
       "      <td>23.00</td>\n",
       "      <td>42.27</td>\n",
       "      <td>85.34</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.77</td>\n",
       "      <td>13.11</td>\n",
       "      <td>234.51</td>\n",
       "      <td>351.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer Cyclical</th>\n",
       "      <td>46.00</td>\n",
       "      <td>53.39</td>\n",
       "      <td>144.48</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.48</td>\n",
       "      <td>13.30</td>\n",
       "      <td>201.24</td>\n",
       "      <td>944.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>61.00</td>\n",
       "      <td>140.32</td>\n",
       "      <td>504.20</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.98</td>\n",
       "      <td>10.77</td>\n",
       "      <td>811.19</td>\n",
       "      <td>3,639.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count   mean    std   min    5%   50%    95%      max\n",
       "sector                                                                       \n",
       "Basic Materials         10.00   7.00  11.98  2.11  2.18  3.12  24.70    40.98\n",
       "Utilities                2.00  14.68   6.27 10.25 10.69 14.68  18.67    19.11\n",
       "Real Estate              5.00  16.46  14.13  4.43  5.05 13.79  35.47    40.27\n",
       "Consumer Defensive       8.00  26.09  19.10  3.50  3.63 26.81  53.04    60.34\n",
       "Energy                   2.00  26.58   0.95 25.91 25.98 26.58  27.18    27.25\n",
       "Healthcare              41.00  26.84  40.72  0.79  2.38 13.21  94.30   227.73\n",
       "Industrials             43.00  27.12  39.13  1.57  2.87 11.62 118.51   202.41\n",
       "Communication Services   4.00  28.42  38.79  2.59  2.62 13.18  75.53    84.71\n",
       "Financial Services      23.00  42.27  85.34  1.72  2.77 13.11 234.51   351.32\n",
       "Consumer Cyclical       46.00  53.39 144.48  1.78  2.48 13.30 201.24   944.18\n",
       "Technology              61.00 140.32 504.20  1.17  1.98 10.77 811.19 3,639.11"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_winners['marketCap'].sort_values(by='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Specialty Retail</th>\n",
       "      <td>7</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health Care Plans</th>\n",
       "      <td>7</td>\n",
       "      <td>9.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Internet Content &amp; Information</th>\n",
       "      <td>8</td>\n",
       "      <td>9.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biotechnology</th>\n",
       "      <td>8</td>\n",
       "      <td>11.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Semiconductors</th>\n",
       "      <td>9</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diversified Industrials</th>\n",
       "      <td>9</td>\n",
       "      <td>6.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medical Instruments &amp; Supplies</th>\n",
       "      <td>9</td>\n",
       "      <td>6.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diagnostics &amp; Research</th>\n",
       "      <td>10</td>\n",
       "      <td>8.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Services</th>\n",
       "      <td>11</td>\n",
       "      <td>6.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Software - Application</th>\n",
       "      <td>16</td>\n",
       "      <td>8.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                count  mean\n",
       "industry                                   \n",
       "Specialty Retail                    7 15.33\n",
       "Health Care Plans                   7  9.10\n",
       "Internet Content & Information      8  9.18\n",
       "Biotechnology                       8 11.22\n",
       "Semiconductors                      9  7.59\n",
       "Diversified Industrials             9  6.22\n",
       "Medical Instruments & Supplies      9  6.75\n",
       "Diagnostics & Research             10  8.74\n",
       "Business Services                  11  6.45\n",
       "Software - Application             16  8.27"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.groupby(by=['industry']).agg(['count', 'mean'])['totalReturn'].sort_values(by='count').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalReturn</th>\n",
       "      <th>shortName</th>\n",
       "      <th>marketCap</th>\n",
       "      <th>sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>4.51</td>\n",
       "      <td>Agilent Technologies, Inc.</td>\n",
       "      <td>24.32</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRKR</th>\n",
       "      <td>4.85</td>\n",
       "      <td>Bruker Corporation</td>\n",
       "      <td>6.64</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DHR</th>\n",
       "      <td>4.66</td>\n",
       "      <td>Danaher Corporation</td>\n",
       "      <td>94.30</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DXCM</th>\n",
       "      <td>27.91</td>\n",
       "      <td>DexCom, Inc.</td>\n",
       "      <td>10.76</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDXX</th>\n",
       "      <td>11.33</td>\n",
       "      <td>IDEXX Laboratories, Inc.</td>\n",
       "      <td>21.14</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILMN</th>\n",
       "      <td>7.40</td>\n",
       "      <td>Illumina, Inc.</td>\n",
       "      <td>46.96</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTD</th>\n",
       "      <td>8.74</td>\n",
       "      <td>Mettler-Toledo International, I</td>\n",
       "      <td>18.39</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEOG</th>\n",
       "      <td>7.28</td>\n",
       "      <td>Neogen Corporation</td>\n",
       "      <td>3.17</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKI</th>\n",
       "      <td>4.35</td>\n",
       "      <td>PerkinElmer, Inc.</td>\n",
       "      <td>10.34</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMO</th>\n",
       "      <td>6.31</td>\n",
       "      <td>Thermo Fisher Scientific Inc</td>\n",
       "      <td>108.20</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        totalReturn                        shortName  marketCap      sector  \\\n",
       "symbol                                                                        \n",
       "A              4.51       Agilent Technologies, Inc.      24.32  Healthcare   \n",
       "BRKR           4.85               Bruker Corporation       6.64  Healthcare   \n",
       "DHR            4.66              Danaher Corporation      94.30  Healthcare   \n",
       "DXCM          27.91                     DexCom, Inc.      10.76  Healthcare   \n",
       "IDXX          11.33         IDEXX Laboratories, Inc.      21.14  Healthcare   \n",
       "ILMN           7.40                   Illumina, Inc.      46.96  Healthcare   \n",
       "MTD            8.74  Mettler-Toledo International, I      18.39  Healthcare   \n",
       "NEOG           7.28               Neogen Corporation       3.17  Healthcare   \n",
       "PKI            4.35                PerkinElmer, Inc.      10.34  Healthcare   \n",
       "TMO            6.31     Thermo Fisher Scientific Inc     108.20  Healthcare   \n",
       "\n",
       "                      industry        country  \n",
       "symbol                                         \n",
       "A       Diagnostics & Research  United States  \n",
       "BRKR    Diagnostics & Research  United States  \n",
       "DHR     Diagnostics & Research  United States  \n",
       "DXCM    Diagnostics & Research  United States  \n",
       "IDXX    Diagnostics & Research  United States  \n",
       "ILMN    Diagnostics & Research  United States  \n",
       "MTD     Diagnostics & Research  United States  \n",
       "NEOG    Diagnostics & Research  United States  \n",
       "PKI     Diagnostics & Research  United States  \n",
       "TMO     Diagnostics & Research  United States  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.loc[joined_df.industry.isin(['Diagnostics & Research']), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### More Sector analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "Engineering & Construction              83.82\n",
       "Packaging & Containers                  90.67\n",
       "Medical Care                            93.75\n",
       "Scientific & Technical Instruments     107.24\n",
       "Electronic Components                  124.90\n",
       "Leisure                                252.71\n",
       "Biotechnology                          286.58\n",
       "Medical Instruments & Supplies         287.91\n",
       "Restaurants                            344.67\n",
       "Business Services                      386.81\n",
       "Communication Equipment                420.76\n",
       "Information Technology Services        430.11\n",
       "Diagnostics & Research                 447.77\n",
       "Medical Devices                        500.25\n",
       "Media - Diversified                    522.33\n",
       "Packaged Foods                         569.99\n",
       "Household & Personal Products          648.31\n",
       "Aerospace & Defense                    681.69\n",
       "Diversified Industrials                795.47\n",
       "Semiconductors                       1,195.61\n",
       "Telecom Services                     1,263.18\n",
       "Software - Infrastructure            1,283.84\n",
       "Software - Application               1,374.74\n",
       "Specialty Retail                     1,727.01\n",
       "Drug Manufacturers - Major           2,165.91\n",
       "Internet Content & Information       6,710.91\n",
       "Name: marketCap, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_sectors = [\n",
    "    'Technology', 'Communication Services', \n",
    "    'Healthcare', 'Consumer Cyclical', 'Consumer Defensive', 'Industrials']\n",
    "size_df = get_focus_tickers(quotes, profile, tgt_sectors)\n",
    "size_df.groupby('industry').sum()['marketCap'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "size\n",
       "micro      0\n",
       "small     32\n",
       "mid      229\n",
       "large    237\n",
       "mega      10\n",
       "Name: marketCap, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_df.groupby(['size', 'sector', ]).count()['marketCap']\n",
    "size_df.groupby('size').count()['marketCap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10990f5c0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Average increase and decrease over a give time period\n",
    "prices = px_close.dropna(subset=[bench])[tickers]\n",
    "excl_tickers = list(prices.iloc[-1].isna().loc[prices.iloc[-1].isna().values].index)\n",
    "prices = prices[excl(prices.columns, excl_tickers)]\n",
    "\n",
    "look_back = context['look_back']\n",
    "prices.pct_change(look_back).where(prices.pct_change(look_back) > 0).mean(1).plot()\n",
    "prices.pct_change(look_back).where(prices.pct_change(look_back) < 0).mean(1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-inf,\n",
       " -0.18970860540866852,\n",
       " -0.12610292434692383,\n",
       " 0.18030300736427307,\n",
       " 0.3123534917831421,\n",
       " inf)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_return_intervals(prices, 120, tresholds=[0.25, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Date and minute based time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freq = '1d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# s1, s2 = '1810.HK', 'AAPL'\n",
    "group_pricing = pd.DataFrame()\n",
    "df1 = get_symbol_pricing(s1, freq, ['close'])\n",
    "df2 = get_symbol_pricing(s2, freq, ['close'])\n",
    "group_pricing = pd.DataFrame(df1)\n",
    "# group_pricing.loc[:, s2] = df2\n",
    "group_pricing = pd.concat([group_pricing, df2], axis=1)\n",
    "group_pricing.describe()\n",
    "# group_pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = config['pricing_path'].format(freq)\n",
    "data_dict = json_load(path + json_ext.format(ticker))\n",
    "\n",
    "tz = data_dict['meta']['exchangeTimezoneName']\n",
    "df = build_px_struct(data_dict, freq)\n",
    "\n",
    "adjClose = data_dict['indicators']['adjclose'][0] if 'adjclose' in  data_dict['indicators'] else 0\n",
    "close = data_dict['indicators']['quote'][0]\n",
    "data_dict.keys(), data_dict['indicators'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.index.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(\n",
    "        data_dict['timestamp'], \n",
    "        unit='s', infer_datetime_format=True)\n",
    "# dates = dates.astype(f'datetime64[ns, {tz}]')\n",
    "# dates.tz_convert('America/New_York')\n",
    "# dates = dates.tz_localize('America/New_York')\n",
    "dates.floor('d' if freq == '1d' else 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "freq = '1d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%time px_close = get_mults_pricing(symbols_list[:10], freq);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# [px_close[x].dropna().tail() for x in px_close.columns]\n",
    "px_close.describe()\n",
    "# px_close.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f'Ticker: {ticker}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "px = get_symbol_pricing(ticker, freq)\n",
    "px.close.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test distribution of Y variable\n",
    "tickers = list(mu.sample_sector_tickers(eqty_symbols, profile, sectors, 50).index)\n",
    "context['grid_search'] = False\n",
    "context['tickers'] = tickers\n",
    "context['train_model'] = True\n",
    "\n",
    "df_large = create_ds(context)\n",
    "\n",
    "df = df_large.copy()\n",
    "df.dropna(subset=[y_col], inplace=True)\n",
    "df[y_col] = discret_rets(df[y_col], cut_range, fwd_ret_labels)\n",
    "df.dropna(subset=[y_col], inplace=True) # no nas in y_col\n",
    "df[y_col] = df[y_col].astype(str) # class as string\n",
    "sample_wgts(df[y_col])\n",
    "\n",
    "pred_X, X_traxin, X_test, y_train, y_test = pre_process_ds(df_large, context)\n",
    "pd.value_counts(discret_rets(df_large.fwdReturn, cut_range, fwd_ret_labels)).sum()\n",
    "pd.value_counts(pd.concat([y_train, y_test], axis=0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test cumulative drawdowns and pulls\n",
    "n = 100\n",
    "r_w = np.random.randn(n).cumsum() + 100\n",
    "l_dd, h_dd, l_p, h_p = max_draw_pull(r_w)\n",
    "\n",
    "plt.plot(r_w)\n",
    "plt.plot(\n",
    "    [l_dd, h_dd], \n",
    "    [r_w[l_dd], r_w[h_dd],], \n",
    "    'o', color='Red', markersize=10)\n",
    "plt.plot(\n",
    "    [l_p, h_p], \n",
    "    [r_w[l_p], r_w[h_p]], \n",
    "    'o', color='Green', markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Retrieves historical pricing\n",
    "secpx = get_symbol_pricing(symbol, freq)\n",
    "secpx.set_index(secpx.index.astype(np.datetime64), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fwd_ss_ret = lambda x, df, arr: df.loc[[y for y in arr[x-1] if y in df.index.tolist()]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# seasonality analysis\n",
    "ss_df = closepx.pct_change().resample('M').sum().to_frame()\n",
    "ss_df['year'], ss_df['month'] = ss_df.index.year, ss_df.index.month\n",
    "ss_df = ss_df.pivot_table(index='year', columns='month').mean()\n",
    "ss_pos = [(x, (x+1) if not (x+1) // 12 else 0, \n",
    "     x+2 if not (x+2) // 12 else x - 10) for x in range(12)]\n",
    "\n",
    "# [fwd_ss_ret(x+1, ss_df['close'], ss_pos) for x in range(12)] # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# apply seasonality, mean return of curr month plus next two\n",
    "secpx['month'] = secpx.index.month\n",
    "secpx['fwdSSRet'] = secpx.loc[:].month.apply(\n",
    "    fwd_ss_ret, args=(ss_df['close'], ss_pos,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "secpx.columns # all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# normalized columns for ML training, still has outliers\n",
    "ml_ds_cols = secpx.describe().loc['50%'][secpx.describe().loc['50%'] < 5].index.tolist()\n",
    "ml_ds_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# prepare ML dataset\n",
    "ml_ds = secpx[ml_ds_cols].copy()\n",
    "\n",
    "class_cols = ['fwdChg1w', 'fwdChg1m', 'fwdChg3m']\n",
    "cut_range = [-1, -0.05, .0, .02, .09, 1.]\n",
    "fwd_ret_labels = [\"bear\", \"short\", \"neutral\", \"long\", \"bull\"]\n",
    "\n",
    "for c in class_cols: ml_ds[c] = pd.cut(secpx[c], cut_range, labels=fwd_ret_labels)\n",
    "ml_ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# drop the predicting class with most nas\n",
    "ml_ds.dropna(inplace=True)\n",
    "ml_ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ml_ds.hist(figsize=(15,15));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ml_ds.to_csv(csv_ext.format('co_price_mom_ds'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
